import asyncio
import base64
import json
import logging
import os
import signal
import struct
import time
from typing import Optional, List, Dict, AsyncIterator, Union
from dataclasses import dataclass
from enum import Enum
# from urllib.parse import urlparse, parse_qs  # REMOVED: no longer needed
from pathlib import Path

import websockets
from websockets.server import WebSocketServerProtocol
import httpx
import webrtcvad
from langdetect import detect
from dotenv import load_dotenv
import jwt

# Voice Session States
class VoiceState(Enum):
    IDLE = "idle"              # Waiting for user input
    USER_SPEAKING = "user"     # ASR active, user is speaking
    ASSISTANT_TTS = "tts"      # Assistant is speaking via TTS

# Import for JWT fallback
from urllib.parse import urlparse, parse_qs

"""
WS PROTOCOL CONTRACT - REALTIME VOICE AI

This contract MUST be maintained at all times. Violations are logged as PROTO VIOLATION.

1. JSON Messages (always allowed):
   - status: connection status
   - tts_start: assistant starts speaking
   - tts_end: assistant stops speaking
   - partial: ASR partial results (frontend only)
   - final: ASR final results
   - llm_*: LLM streaming deltas
   - ack: acknowledgment sounds

2. Binary Messages (ONLY allowed between tts_start and tts_end):
   - Format: WAV or AUD0(WAV/PCM16)
   - Size: variable, but complete WAV files
   - Ordering: must be sent through ws_send() for strict ordering

3. Voice State Machine:
   IDLE ‚Üí USER_SPEAKING ‚Üí ASSISTANT_TTS ‚Üí IDLE (loop)

4. PCM from User:
   - Frame size: EXACTLY 640 bytes (20ms @ 16kHz int16 mono)
   - Allowed ONLY when voice_state != ASSISTANT_TTS
   - Dropped otherwise (logged as violation)

5. TTS Ordering Invariant:
   tts_start ‚Üí [binary audio chunks 1..N] ‚Üí tts_end
   NEVER: binary before tts_start, tts_end before binary, overlapping TTS

6. ASR Invariants:
   - ASR warmup after TTS (200ms)
   - No vad.reset() during conversation
   - ASR enabled only when voice_state != ASSISTANT_TTS

7. Event Normalization:
   - Only 'user' and 'assistant' events reach Voice Control
   - Events filtered and validated before sending
   - Empty texts dropped, roles validated

Violations MUST be logged and fixed immediately.
"""

from vosk import Model, KaldiRecognizer, SetLogLevel
from agents import AGENTS
import tts_silero

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger("ws")
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è event loop –¥–ª—è Linux
try:
    import uvloop
    asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())
except ImportError:
    pass  # uvloop –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π asyncio

# Feature flag –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è VoiceAsk (legacy)
VOICE_API_MODE = os.getenv('VOICE_API_MODE', 'true').lower() == 'true'
if VOICE_API_MODE:
    logger.info("üéØ VOICE API MODE: ENABLED (—Ç–æ–ª—å–∫–æ WS realtime)")
else:
    logger.info("üîÑ VOICE API MODE: DISABLED (legacy VoiceAsk –∞–∫—Ç–∏–≤–µ–Ω)")

# Voice Control integration
VOICE_CONTROL_URL = os.getenv("VOICE_CONTROL_URL", "http://localhost:8080")
VOICE_INTERNAL_KEY = os.getenv("VOICE_INTERNAL_KEY", "")

def normalize_event(*, event_type: str, role: str, text: str | None, timestamp: float | None = None) -> dict | None:
    """
    –ü—Ä–∏–≤–æ–¥–∏—Ç —Å–æ–±—ã—Ç–∏–µ –∫ –≤–∞–ª–∏–¥–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É Voice Control.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç None, –µ—Å–ª–∏ —Å–æ–±—ã—Ç–∏–µ –Ω–µ–≤–∞–ª–∏–¥–Ω–æ –∏ –Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ.
    """
    if not text:
        return None

    text = text.strip()
    if not text:
        return None

    if role not in ("user", "assistant"):
        return None

    return {
        "role": role,
        "text": text,
        "utterance_id": None,  # –ü–æ–∫–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º utterance_id –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã
        "ts": int((timestamp or time.time()) * 1000),
    }

async def push_event_to_voice_control(session_id: str, event_payload: dict):
    """–û—Ç–ø—Ä–∞–≤–∏—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ –¥–∏–∞–ª–æ–≥–∞ –≤ Voice Control"""
    if not VOICE_INTERNAL_KEY or not VOICE_CONTROL_URL:
        return

    if not event_payload:
        print(f"[EVENT] Dropped invalid event for session {session_id}")
        return

    url = f"{VOICE_CONTROL_URL}/v1/internal/voice/sessions/{session_id}/events"

    try:
        async with httpx.AsyncClient(timeout=httpx.Timeout(2.0)) as client:
            response = await client.post(
                url,
                headers={"X-Internal-Key": VOICE_INTERNAL_KEY, "Content-Type": "application/json"},
                json=event_payload,
            )
            if response.status_code == 200:
                print(f"[VOICE_CONTROL] Event pushed: {event_payload.get('role')} ({len(event_payload.get('text', ''))} chars)")
            else:
                print(f"[VOICE_CONTROL] Push failed: HTTP {response.status_code}")
    except Exception as e:
        # –ù–µ –±–ª–æ–∫–∏—Ä—É–µ–º realtime, –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º
        print(f"[VOICE_CONTROL] Push error: {e}")

HOST = os.getenv("HOST", "0.0.0.0")
PORT = int(os.getenv("PORT", "2700"))
MODEL_PATH = os.getenv("MODEL_PATH", "/Users/artembutko/Desktop/VS/models/vosk-model-small-ru-0.22")
DEFAULT_SAMPLE_RATE = int(os.getenv("SAMPLE_RATE", "16000"))

# LLM API configuration (OpenAI by default)
LLM_PROVIDER = os.getenv("LLM_PROVIDER", "openai")  # openai, deepseek, or other
LLM_API_KEY = os.getenv("LLM_API_KEY")
if not LLM_API_KEY:
    raise RuntimeError("LLM_API_KEY is not set")

LLM_BASE_URL = os.getenv("LLM_BASE_URL", "https://api.openai.com")
OPENAI_BASE_URL = LLM_BASE_URL  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –∫–æ–¥–æ–º
OPENAI_API_KEY = LLM_API_KEY  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –∫–æ–¥–æ–º
LLM_MODEL = os.getenv("LLM_MODEL", "gpt-3.5-turbo")
OPENAI_MODEL = LLM_MODEL  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –∫–æ–¥–æ–º
MAX_TOKENS = int(os.getenv("MAX_TOKENS", "160"))
TEMPERATURE = float(os.getenv("TEMPERATURE", "0.3"))

# TTS –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
TTS_PROVIDER = os.getenv("TTS_PROVIDER", "local")  # local (silero) or openai
TTS_BASE_URL = os.getenv("TTS_BASE_URL", "http://127.0.0.1:8002")
TTS_API_KEY = os.getenv("TTS_API_KEY")  # –¥–ª—è –≤–Ω–µ—à–Ω–∏—Ö API
TTS_MODEL = os.getenv("TTS_MODEL", "silero_ru")
TTS_VOICE = os.getenv("TTS_VOICE", "eugene")
TTS_SPEED = float(os.getenv("TTS_SPEED", "0.93"))
TTS_EMOTION = os.getenv("TTS_EMOTION", "neutral")
TTS_PAUSE = float(os.getenv("TTS_PAUSE", "0.12"))
TTS_TIMEOUT = float(os.getenv("TTS_TIMEOUT", "10"))

# JWT Configuration –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–æ–∫–µ–Ω–æ–≤
VOICE_JWT_SECRET = os.getenv("VOICE_JWT_SECRET", "super-secret-voice-2026")
# –õ–æ–∫–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º: –æ—Ç–∫–ª—é—á–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É —Ç–æ–∫–µ–Ω–∞ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
LOCAL_MODE = os.getenv("LOCAL_MODE", "true").lower() == "true"
DISABLE_AUTH = os.getenv("DISABLE_AUTH", "true").lower() == "true"
VOICE_JWT_ISSUER = os.getenv("VOICE_JWT_ISSUER", "voice-control")
VOICE_JWT_AUD = "voice-ws"

# TTS Settings dataclass –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ TTSBackend
@dataclass(frozen=True)
class TTSSettings:
    model: str
    voice: str
    speed: float
    emotion: str
    pause: float
    timeout: float

# –ë–∏–Ω–∞—Ä–Ω—ã–π –ø—Ä–æ—Ç–æ–∫–æ–ª –∞—É–¥–∏–æ
MIME_WAV = 1
AUDIO_MAGIC = b"AUD0"

# –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞ sample rate
ALLOWED_SAMPLE_RATE = 16000

def normalize_sample_rate(requested: int | None) -> int:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç sample_rate: —Å–µ—Ä–≤–µ—Ä –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ 16000 Hz PCM16 mono"""
    if requested != ALLOWED_SAMPLE_RATE:
        print(f"[CONFIG] Client requested sample_rate={requested}, forcing to {ALLOWED_SAMPLE_RATE}")
        return ALLOWED_SAMPLE_RATE
    return requested

# –°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞
from dataclasses import dataclass, field

@dataclass
class Turn:
    role: str            # "user" | "assistant"
    text: str
    ts: int = field(default_factory=lambda: int(time.time() * 1000))
    utterance_id: int | None = None

@dataclass
class SessionState:
    session_id: str
    agent_id: str
    turns: list[Turn] = field(default_factory=list)
    llm_buffers: dict[int, str] = field(default_factory=dict)
    summary: str = ""
    ended: bool = False
    ended_at_ms: int | None = None

    def add_turn(self, role: str, text: str, utterance_id: int | None = None):
        text = (text or "").strip()
        if not text:
            return
        self.turns.append(Turn(role=role, text=text, utterance_id=utterance_id))
        print(f"[SESSION:{self.session_id}] Added {role} turn: '{text[:50]}...'")

    def build_llm_messages(self, system_prompt: str, max_turns: int = 12):
        history = self.turns[-max_turns:]
        messages = [{"role": "system", "content": system_prompt}]
        for t in history:
            messages.append({"role": "user" if t.role == "user" else "assistant", "content": t.text})
        return messages

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Ä–µ–µ—Å—Ç—Ä —Å–µ—Å—Å–∏–π
SESSIONS: dict[str, SessionState] = {}

def build_session_summary(session: SessionState) -> str:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç —Ä–µ–∑—é–º–µ —Å–µ—Å—Å–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞"""
    turns = session.turns
    user_facts = []
    emotions = []
    topics = []

    # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ä–µ–ø–ª–∏–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    for t in turns:
        if t.role == "user":
            user_facts.append(t.text)
            # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π
            text_lower = t.text.lower()
            if any(word in text_lower for word in ["—É—Å—Ç–∞–ª", "–≥—Ä—É—Å—Ç–Ω–æ", "–ø–ª–æ—Ö–æ", "—Å—Ç—Ä–µ—Å—Å", "—Ç—Ä–µ–≤–æ–≥–∞"]):
                emotions.append("—Ç—Ä–µ–≤–æ–∂–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ")
            elif any(word in text_lower for word in ["—Ö–æ—Ä–æ—à–æ", "–æ—Ç–ª–∏—á–Ω–æ", "–≤ –ø–æ—Ä—è–¥–∫–µ", "—Å–ø–∞—Å–∏–±–æ"]):
                emotions.append("–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ")
            else:
                emotions.append("–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ")

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—é–º–µ
    return (
        "–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ —Å–µ—Å—Å–∏–∏:\n"
        f"–û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã: {', '.join(topics[:3] if topics else ['–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è'])[:50]}\n"
        f"–°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {', '.join(set(emotions))[:50]}\n"
        f"–ö–ª—é—á–µ–≤—ã–µ –≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏—è: {' | '.join(user_facts[-3:])[:100]}"
    )

# Health check –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
HEALTH_PORT = int(os.getenv("HEALTH_PORT", "8081"))

# VAD –∏ endpointing –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
FRAME_MS = int(os.getenv("FRAME_MS", "20"))          # 10/20/30 ms
VAD_MODE = int(os.getenv("VAD_MODE", "2"))           # 0..3 (0 –º—è–≥–∫–∏–π, 3 –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π)
EARLY_PAUSE_MS = int(os.getenv("EARLY_PAUSE_MS", "300"))   # –£–º–µ–Ω—å—à–µ–Ω–æ: –±—ã—Å—Ç—Ä–µ–µ —Å—Ç–∞—Ä—Ç
FINAL_PAUSE_MS = int(os.getenv("FINAL_PAUSE_MS", "800"))   # –£–º–µ–Ω—å—à–µ–Ω–æ: –±—ã—Å—Ç—Ä–µ–µ —Ñ–∏–Ω–∞–ª
STABLE_MS = int(os.getenv("STABLE_MS", "250"))
PARTIAL_RATE_LIMIT_MS = int(os.getenv("PARTIAL_RATE_LIMIT_MS", "150"))
MIN_WORDS_EARLY = int(os.getenv("MIN_WORDS_EARLY", "1"))   # –ë—ã–ª–æ 3: —Ç–µ–ø–µ—Ä—å —Ä–µ–∞–≥–∏—Ä—É–µ—Ç –Ω–∞ 1 —Å–ª–æ–≤–æ
MIN_CHARS_EARLY = int(os.getenv("MIN_CHARS_EARLY", "3"))   # –ë—ã–ª–æ 12: —Ç–µ–ø–µ—Ä—å —Ä–µ–∞–≥–∏—Ä—É–µ—Ç –Ω–∞ "–î–∞", "–ù–µ—Ç"
RESTART_DEBOUNCE_MS = int(os.getenv("RESTART_DEBOUNCE_MS", "200")) # –ë—ã–ª–æ 1200! –¢–µ–ø–µ—Ä—å –º–≥–Ω–æ–≤–µ–Ω–Ω–æ.

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π HTTP –∫–ª–∏–µ–Ω—Ç –¥–ª—è DeepSeek (keep-alive)
_deepseek_http: httpx.AsyncClient | None = None

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π HTTP –∫–ª–∏–µ–Ω—Ç –¥–ª—è TTS (keep-alive)
_tts_http: httpx.AsyncClient | None = None

# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å Origin (–ø—Ä–æ–¥–æ–≤–∞—è –≥–∏–≥–∏–µ–Ω–∞)
ALLOWED_ORIGINS = set(
    o.strip() for o in os.getenv("ALLOWED_ORIGINS", "").split(",") if o.strip()
)

# –ß—Ç–æ–±—ã event loop –Ω–µ ‚Äú—É–º–∏—Ä–∞–ª‚Äù –Ω–∞ CPU-bound –¥–µ–∫–æ–¥–∏–Ω–≥–µ, –≥–æ–Ω—è–µ–º –¥–µ–∫–æ–¥ –≤ thread pool
DECODE_IN_THREAD = os.getenv("DECODE_IN_THREAD", "1") == "1"

print(f"[boot] loading model: {MODEL_PATH}")
MODEL = Model(MODEL_PATH)
print("[boot] model loaded")


def verify_ws_token(token: str) -> dict:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç JWT —Ç–æ–∫–µ–Ω –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç payload"""
    return jwt.decode(
        token,
        VOICE_JWT_SECRET,
        algorithms=["HS256"],
        audience=VOICE_JWT_AUD,
        issuer=VOICE_JWT_ISSUER,
    )


def build_llm_payload(question: str, *, model: str, system_prompt: str, max_tokens: int, temperature: float) -> dict:
    """–°—Ç—Ä–æ–∏—Ç payload –¥–ª—è LLM API —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∞–≥–µ–Ω—Ç–∞"""
    return {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": question},
        ],
        "max_tokens": max_tokens,
        "temperature": temperature,
        "stream": True,  # –í–ö–õ–Æ–ß–ê–ï–ú STREAMING –¥–ª—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ TTFT
    }

async def init_openai_http():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π HTTP –∫–ª–∏–µ–Ω—Ç –¥–ª—è OpenAI —Å keep-alive"""
    global _deepseek_http
    if _deepseek_http is None:
        _deepseek_http = httpx.AsyncClient(
            base_url=OPENAI_BASE_URL,
            headers={
                "Authorization": f"Bearer {OPENAI_API_KEY}",
                "Content-Type": "application/json",
            },
            timeout=httpx.Timeout(30.0, connect=5.0),
            http2=True,
            limits=httpx.Limits(
                max_connections=100,
                max_keepalive_connections=20,
                keepalive_expiry=60.0,
            ),
        )

async def close_openai_http():
    """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π HTTP –∫–ª–∏–µ–Ω—Ç –¥–ª—è OpenAI"""
    global _deepseek_http
    if _deepseek_http is not None:
        await _deepseek_http.aclose()
        _deepseek_http = None

# TTS HTTP –∫–ª–∏–µ–Ω—Ç –¥–ª—è –≤–Ω–µ—à–Ω–∏—Ö API
_tts_api_http: httpx.AsyncClient | None = None

async def init_tts_api_http():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç HTTP –∫–ª–∏–µ–Ω—Ç –¥–ª—è –≤–Ω–µ—à–Ω–∏—Ö TTS API"""
    global _tts_api_http
    if _tts_api_http is None:
        _tts_api_http = httpx.AsyncClient(
            timeout=httpx.Timeout(30.0, connect=5.0),
            http2=True,
            limits=httpx.Limits(
                max_connections=50,
                max_keepalive_connections=20,
                keepalive_expiry=60.0,
            ),
        )

async def close_tts_api_http():
    """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç HTTP –∫–ª–∏–µ–Ω—Ç –¥–ª—è –≤–Ω–µ—à–Ω–∏—Ö TTS API"""
    global _tts_api_http
    if _tts_api_http is not None:
        await _tts_api_http.aclose()
        _tts_api_http = None

async def init_tts_http():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π HTTP –∫–ª–∏–µ–Ω—Ç –¥–ª—è TTS"""
    global _tts_http
    if _tts_http is None:
        _tts_http = httpx.AsyncClient(
            base_url=TTS_BASE_URL,
            timeout=httpx.Timeout(TTS_TIMEOUT, connect=2.0),
            limits=httpx.Limits(
                max_connections=50,
                max_keepalive_connections=10,
                keepalive_expiry=60.0,
            ),
        )

async def close_tts_http():
    """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π HTTP –∫–ª–∏–µ–Ω—Ç –¥–ª—è TTS"""
    global _tts_http
    if _tts_http is not None:
        await _tts_http.aclose()
        _tts_http = None

async def health_server():
    async def handle(reader, writer):
        try:
            data = await reader.read(4096)
            if not data:
                writer.close()
                return

            # parse first line: METHOD PATH HTTP/1.1
            line0 = data.split(b"\r\n", 1)[0].decode("utf-8", "ignore")
            parts = line0.split()
            method = parts[0] if len(parts) > 0 else ""
            path = parts[1] if len(parts) > 1 else ""

            # --- /health ---
            if method == "GET" and path.startswith("/health"):
                body = b"ok"
                writer.write(
                    b"HTTP/1.1 200 OK\r\n"
                    b"Content-Type: text/plain\r\n"
                    b"Content-Length: 2\r\n\r\n" + body
                )
                await writer.drain()
                writer.close()
                return

            # --- /v1/voice/sessions/{id}/summary ---
            if method == "GET" and path.startswith("/v1/voice/sessions/") and path.endswith("/summary"):
                session_id = path.split("/v1/voice/sessions/", 1)[1].rsplit("/summary", 1)[0]
                sess = SESSIONS.get(session_id)
                if not sess:
                    body = json.dumps({"ok": False, "error": "unknown_session"}).encode()
                    writer.write(
                        b"HTTP/1.1 404 Not Found\r\n"
                        b"Content-Type: application/json\r\n"
                        b"Content-Length: " + str(len(body)).encode() + b"\r\n\r\n" + body
                    )
                    await writer.drain()
                    writer.close()
                    return

                body = json.dumps({"ok": True, "session_id": session_id, "summary": sess.summary}).encode("utf-8")
                writer.write(
                    b"HTTP/1.1 200 OK\r\n"
                    b"Content-Type: application/json\r\n"
                    b"Content-Length: " + str(len(body)).encode() + b"\r\n\r\n" + body
                )
                await writer.drain()
                writer.close()
                return

            # --- /v1/voice/sessions/{id}/end ---
            if method == "POST" and path.startswith("/v1/voice/sessions/") and path.endswith("/end"):
                session_id = path.split("/v1/voice/sessions/", 1)[1].rsplit("/end", 1)[0]
                sess = SESSIONS.get(session_id)
                if not sess:
                    body = json.dumps({"ok": False, "error": "unknown_session"}).encode()
                    writer.write(
                        b"HTTP/1.1 404 Not Found\r\n"
                        b"Content-Type: application/json\r\n"
                        b"Content-Length: " + str(len(body)).encode() + b"\r\n\r\n" + body
                    )
                    await writer.drain()
                    writer.close()
                    return

                if not sess.summary and sess.turns:
                    try:
                        sess.summary = build_session_summary(sess)
                    except Exception as e:
                        sess.summary = f"summary_error: {e}"

                sess.ended = True
                sess.ended_at_ms = now_ms()

                body = json.dumps({"ok": True, "session_id": session_id, "summary": sess.summary}).encode("utf-8")
                writer.write(
                    b"HTTP/1.1 200 OK\r\n"
                    b"Content-Type: application/json\r\n"
                    b"Content-Length: " + str(len(body)).encode() + b"\r\n\r\n" + body
                )
                await writer.drain()
                writer.close()
                return

            # default 404
            body = b"not found"
            writer.write(
                    b"HTTP/1.1 404 Not Found\r\n"
                    b"Content-Type: text/plain\r\n"
                b"Content-Length: 9\r\n\r\n" + body
                )
            await writer.drain()
        except Exception as e:
            print(f"[HEALTH] –û—à–∏–±–∫–∞: {e}")
        finally:
            try:
                writer.close()
            except:
                pass

    try:
        srv = await asyncio.start_server(handle, "0.0.0.0", HEALTH_PORT)
        print(f"[HTTP] Health/API —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É {HEALTH_PORT}")
        return srv
    except Exception as e:
        print(f"[HTTP] –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å health/api —Å–µ—Ä–≤–µ—Ä: {e}")
        return None

async def openai_stream(
    question: str = None,
    *,
    messages: list[dict] = None,
    model: str = None,
    system_prompt: str = None,
    max_tokens: int = None,
    temperature: float = None,
):
    """
    Streaming –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–ª—è OpenAI API.
    Yield'–∏—Ç —Ç–æ–∫–µ–Ω—ã –ø–æ –º–µ—Ä–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ TTFT.

    - –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–ª–∏ messages -> –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
    - –ò–Ω–∞—á–µ —Å–æ–±–∏—Ä–∞–µ–º messages –∏–∑ system_prompt + question (legacy)
    """
    # –ï—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –¥–µ—Ñ–æ–ª—Ç—ã
    if model is None:
        model = LLM_MODEL
    if max_tokens is None:
        max_tokens = MAX_TOKENS
    if temperature is None:
        temperature = TEMPERATURE

    # –°–¢–†–û–ò–ú MESSAGES
    if messages is None:
        if question is None:
            raise ValueError("Either messages or question must be provided")
        if system_prompt is None:
            system_prompt = "–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É. 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ë–µ–∑ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π."
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": question},
        ]

    print(f"[OPENAI] –ù–∞—á–∏–Ω–∞–µ–º streaming –¥–ª—è: {len(messages)} messages")
    await init_openai_http()
    assert _deepseek_http is not None

    payload = {
        "model": model,
        "messages": messages,
        "stream": True,
        "temperature": temperature,
        "max_tokens": max_tokens,
    }
    print(f"[OPENAI] Payload ready, streaming...")

    try:
        async with _deepseek_http.stream("POST", "/v1/chat/completions", json=payload) as r:
            print(f"[OPENAI] Response status: {r.status_code}")
            r.raise_for_status()

            async for line in r.aiter_lines():
                if not line:
                    continue
                if line.startswith(":"):
                    # keep-alive comment, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º
                    continue
                if not line.startswith("data:"):
                    continue

                data = line[len("data:"):].strip()
                if data == "[DONE]":
                    print("[OPENAI] Streaming completed")
                    break

                try:
                    chunk = json.loads(data)
                    choices = chunk.get("choices") or []
                    if not choices:
                        continue

                    delta = (choices[0].get("delta") or {})
                    text = delta.get("content")
                    if text:
                        print(f"[OPENAI] Yielding token: '{text}'")
                        yield text
                except json.JSONDecodeError:
                    continue  # –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –±–∏—Ç—ã–µ —á–∞–Ω–∫–∏
    except Exception as e:
        print(f"[OPENAI] Error in streaming: {e}")
        raise


def build_recognizer(sample_rate: int, phrase_list: Optional[list] = None, words: bool = False) -> KaldiRecognizer:
    if phrase_list:
        # grammar / phrase list: –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å, —É—Å–∫–æ—Ä—è–µ—Ç/—É–ª—É—á—à–∞–µ—Ç –≤ —É–∑–∫–∏—Ö –¥–æ–º–µ–Ω–∞—Ö
        rec = KaldiRecognizer(MODEL, sample_rate, json.dumps(phrase_list, ensure_ascii=False))
    else:
        rec = KaldiRecognizer(MODEL, sample_rate)
    rec.SetWords(bool(words))
    return rec

def now_ms() -> int:
    """–¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö"""
    return int(time.time() * 1000)

def frame_bytes(sample_rate: int, frame_ms: int) -> int:
    """–†–∞–∑–º–µ—Ä —Ñ—Ä–µ–π–º–∞ –≤ –±–∞–π—Ç–∞—Ö –¥–ª—è mono PCM16"""
    return int(sample_rate * frame_ms / 1000) * 2

def word_count(text: str) -> int:
    """–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ"""
    return len([w for w in text.strip().split() if w])

def is_meaningful(text: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∏–º–µ–µ—Ç –ª–∏ —Ç–µ–∫—Å—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π —Å–º—ã—Å–ª –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ—Ç–≤–µ—Ç–∞"""
    t = (text or "").strip()
    return (len(t) >= MIN_CHARS_EARLY) and (word_count(t) >= MIN_WORDS_EARLY)

async def call_with_retry(fn, retries=1, backoff=0.2):
    """–ü—Ä–æ—Å—Ç–æ–π retry –¥–ª—è —Å–µ—Ç–µ–≤—ã—Ö –≤—ã–∑–æ–≤–æ–≤"""
    for attempt in range(retries + 1):
        try:
            return await fn()
        except (httpx.ConnectError, httpx.TimeoutException) as e:
            if attempt == retries:
                raise
            print(f"[RETRY] –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}, –∂–¥–µ–º {backoff}s")
            await asyncio.sleep(backoff)
            backoff *= 2
        except httpx.HTTPStatusError as e:
            # –ù–µ —Ä–µ—Ç—Ä–∞–∏–º 4xx –æ—à–∏–±–∫–∏
            if e.response.status_code < 500:
                raise
            if attempt == retries:
                raise
            print(f"[RETRY] –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}, –∂–¥–µ–º {backoff}s")
            await asyncio.sleep(backoff)
            backoff *= 2

def split_for_tts(buf: str) -> tuple[list[str], str]:
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç –±—É—Ñ–µ—Ä —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏ –¥–ª—è TTS.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–≥–æ—Ç–æ–≤—ã–µ_—á–∞–Ω–∫–∏, –æ—Å—Ç–∞—Ç–æ–∫_–±—É—Ñ–µ—Ä–∞).
    """
    N = 120  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —á–∞–Ω–∫–∞ –≤ —Å–∏–º–≤–æ–ª–∞—Ö
    seps = [".", "!", "?", "\n"]

    out = []
    while True:
        cut = -1
        # –ò—â–µ–º –±–ª–∏–∂–∞–π—à–∏–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        for s in seps:
            idx = buf.find(s)
            if idx != -1:
                cut = idx if cut == -1 else min(cut, idx)

        if cut != -1:
            # –ù–∞—à–ª–∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å - –æ—Ç—Ä–µ–∑–∞–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
            chunk = buf[:cut+1].strip()
            buf = buf[cut+1:].lstrip()
            if chunk:
                out.append(chunk)
            continue

        if len(buf) >= N:
            # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–ø—è—Ç—É—é –∏–ª–∏ –ø—Ä–æ–±–µ–ª –ø–µ—Ä–µ–¥ –ª–∏–º–∏—Ç–æ–º –¥–ª—è –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è
            space_cut = buf.rfind(' ', 0, N)
            comma_cut = buf.rfind(',', 0, N)
            best_cut = max(space_cut, comma_cut)
            
            if best_cut > 50:  # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Ö–æ—Ä–æ—à—É—é —Ç–æ—á–∫—É —Ä–∞–∑–±–∏–µ–Ω–∏—è
                chunk = buf[:best_cut+1].strip()
                buf = buf[best_cut+1:].lstrip()
            else:
                # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ª–∏–º–∏—Ç—É
                chunk = buf[:N].strip()
                buf = buf[N:].lstrip()
            
            if chunk:
                out.append(chunk)
            continue

        break

    return out, buf

class TTSBackend:
    """Backend –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å TTS API"""

    def __init__(self):
        self.cache: dict[str, bytes] = {}

    async def warmup_ack(self):
        """–ü—Ä–æ–≥—Ä–µ–≤–∞–µ–º –∏ –∫–µ—à–∏—Ä—É–µ–º ACK —Ñ—Ä–∞–∑—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"""
        self.ack_texts = (
            "–ü–æ–Ω–∏–º–∞—é –æ —á–µ–º —Ä–µ—á—å.", "–î–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä–µ–º—Å—è.", "–°–ª—É—à–∞—é –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ.",
            "–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–∑–≥–æ–≤–æ—Ä.", "–Ø –≥–æ—Ç–æ–≤.", "–í–Ω–∏–∫–∞—é –≤ —Å—É—Ç—å.",
            "–†–∞–∑–±–∏—Ä–∞—é—Å—å –≤ –≤–æ–ø—Ä–æ—Å–µ.", "–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.", "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –¥–∞–Ω–Ω—ã–µ.",
            "–ò–∑—É—á–∞—é –¥–µ—Ç–∞–ª–∏.", "–ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∏—Ä—É—é—Å—å –Ω–∞ —Ç–µ–º–µ.", "–í–æ—Å–ø—Ä–∏–Ω–∏–º–∞—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.",
            "–û—Å–º—ã—Å–ª–∏–≤–∞—é –≤–æ–ø—Ä–æ—Å.", "–ü—Ä–∏–Ω–∏–º–∞—é –∫ —Å–≤–µ–¥–µ–Ω–∏—é.", "–ò–∑–≤–ª–µ–∫–∞—é —Å–º—ã—Å–ª.",
            "–ü—Ä–æ—Ä–∞–±–∞—Ç—ã–≤–∞—é –¥–µ—Ç–∞–ª–∏.", "–í–Ω–∏–∫–∞—é –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç.", "–£—è—Å–Ω—è—é –∑–∞–¥–∞—á—É.",
            "–ü—Ä–∏–Ω–∏–º–∞—é –∑–∞–ø—Ä–æ—Å.", "–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–∏—Ç—É–∞—Ü–∏—é."
        )
        for txt in self.ack_texts:
            try:
                self.cache[txt] = await self.synthesize_wav(txt)
                print(f"[TTS] ACK –∫–µ—à–∏—Ä–æ–≤–∞–Ω: '{txt}' ({len(self.cache[txt])} bytes)")
            except Exception as e:
                print(f"[TTS] –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≥—Ä–µ—Ç—å ACK '{txt}': {e}")

    def get_random_ack_text(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—É—é ACK —Ñ—Ä–∞–∑—É"""
        import random
        return random.choice(self.ack_texts)

    def get_random_ack_wav(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—É—é ACK —Ñ—Ä–∞–∑—É –∏ –µ—ë WAV –¥–∞–Ω–Ω—ã–µ"""
        ack_text = self.get_random_ack_text()
        return ack_text, self.cache.get(ack_text)

    async def _synthesize_openai_tts(self, text: str, lang: Optional[str] = None, settings: Optional[TTSSettings] = None) -> bytes:
        """–°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç —Ä–µ—á—å —á–µ—Ä–µ–∑ OpenAI TTS API"""
        # –ï—Å–ª–∏ settings –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –¥–µ—Ñ–æ–ª—Ç—ã
        if settings is None:
            settings = TTSSettings(
                model=TTS_MODEL,
                voice=TTS_VOICE,
                speed=TTS_SPEED,
                emotion=TTS_EMOTION,
                pause=TTS_PAUSE,
                timeout=TTS_TIMEOUT,
            )
        
        await init_tts_api_http()
        assert _tts_api_http is not None

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–æ–ª–æ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —è–∑—ã–∫–∞
        voice = "alloy"  # default voice
        if lang and lang.startswith('ru'):
            voice = "alloy"  # OpenAI –ø–æ–∫–∞ –Ω–µ –∏–º–µ–µ—Ç —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –≥–æ–ª–æ—Å–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º alloy
        elif lang and lang.startswith('en'):
            voice = "alloy"  # –∏–ª–∏ "echo", "fable", "onyx", "nova", "shimmer"

        # –ú–æ–¥–µ–ª—å –¥–ª—è OpenAI TTS
        model = "tts-1"  # –∏–ª–∏ "tts-1-hd" –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞

        payload = {
            "model": model,
            "input": text,
            "voice": voice,
            "response_format": "wav",
            "speed": settings.speed
        }

        headers = {
            "Authorization": f"Bearer {TTS_API_KEY}",
            "Content-Type": "application/json"
        }

        try:
            response = await _tts_api_http.post(
                "https://api.openai.com/v1/audio/speech",
                json=payload,
                headers=headers
            )
            response.raise_for_status()
            print(f"[TTS] OpenAI TTS synthesized: '{text[:50]}...' ({len(response.content)} bytes)")
            return response.content
        except Exception as e:
            print(f"[TTS] OpenAI TTS failed: {e}")
            # Fallback to local TTS if available
            if TTS_PROVIDER == "openai":
                raise
            print("[TTS] Falling back to local TTS")
            return await self._synthesize_local_tts(text, lang)

    async def synthesize_wav(self, text: str, lang: Optional[str] = None, settings: Optional[TTSSettings] = None) -> bytes:
        """–°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç WAV –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —è–∑—ã–∫–∞"""
        # –ï—Å–ª–∏ settings –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –¥–µ—Ñ–æ–ª—Ç—ã
        if settings is None:
            settings = TTSSettings(
                model=TTS_MODEL,
                voice=TTS_VOICE,
                speed=TTS_SPEED,
                emotion=TTS_EMOTION,
                pause=TTS_PAUSE,
                timeout=TTS_TIMEOUT,
            )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
        if text in self.cache:
            return self.cache[text]

        # –í—ã–±–æ—Ä –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ TTS
        if TTS_PROVIDER == "openai":
            return await self._synthesize_openai_tts(text, lang, settings)
        else:
            # –õ–æ–∫–∞–ª—å–Ω—ã–π TTS (Silero)
            await init_tts_http()
            assert _tts_http is not None

        # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω
        if lang is None:
            try:
                lang = detect(text.strip())
                print(f"[TTS] Detected language: {lang} for text: '{text[:50]}...'")
            except Exception as e:
                print(f"[TTS] Language detection failed: {e}, using 'ru' as default")
                lang = "ru"

        return await self._synthesize_local_tts(text, lang, settings)

    async def _synthesize_local_tts(self, text: str, lang: Optional[str] = None, settings: Optional[TTSSettings] = None) -> bytes:
        """–õ–æ–∫–∞–ª—å–Ω—ã–π TTS —á–µ—Ä–µ–∑ Silero (–ø—Ä—è–º–æ–π –≤—ã–∑–æ–≤ –±–µ–∑ HTTP)"""
        # –ï—Å–ª–∏ settings –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –¥–µ—Ñ–æ–ª—Ç—ã
        if settings is None:
            settings = TTSSettings(
                model=TTS_MODEL,
                voice=TTS_VOICE,
                speed=TTS_SPEED,
                emotion=TTS_EMOTION,
                pause=TTS_PAUSE,
                timeout=TTS_TIMEOUT,
            )
        
        try:
            # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –∏ –≥–æ–ª–æ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —è–∑—ã–∫–∞
            model_to_use = settings.model
            voice_to_use = settings.voice

            if lang and lang.startswith('en'):
                if settings.model == "silero_ru":
                    model_to_use = "silero_en"
                    voice_to_use = "en_0"  # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π –≥–æ–ª–æ—Å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                elif settings.model == "silero_en":
                    voice_to_use = settings.voice if settings.voice.startswith('en_') else "en_0"
            elif lang and lang.startswith('ru'):
                if settings.model == "silero_en":
                    model_to_use = "silero_ru"
                    voice_to_use = "eugene"  # –†—É—Å—Å–∫–∏–π –≥–æ–ª–æ—Å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                elif settings.model == "silero_ru":
                    voice_to_use = settings.voice if settings.voice in ["eugene", "aidar", "xenia", "baya", "kseniya"] else "eugene"

            print(f"[TTS] Using direct Silero: model={model_to_use}, voice={voice_to_use}, lang={lang}")
            
            # –ü—Ä—è–º–æ–π –≤—ã–∑–æ–≤ tts_silero –±–µ–∑ HTTP
            wav_bytes = await tts_silero.synthesize_wav(
                text=text,
                model_name=model_to_use,
                voice=voice_to_use,
                speed=settings.speed,
                emotion=settings.emotion,
                pause=settings.pause
            )
            
            print(f"[TTS] Synthesized {len(wav_bytes)} bytes directly")
            return wav_bytes
            
        except Exception as e:
            print(f"[TTS] Direct synthesis failed: {e}")
            # Fallback: –ø–æ–ø—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ HTTP, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
            try:
                await init_tts_http()
                if _tts_http is not None:
                    print(f"[TTS] Trying HTTP fallback...")
                    r = await _tts_http.post("/tts_wav", json={
                        "text": text,
                        "model": model_to_use,
                        "voice": voice_to_use,
                        "speed": settings.speed,
                        "emotion": settings.emotion,
                        "pause_between_sentences": settings.pause,
                    }, timeout=5.0)
                    r.raise_for_status()
                    return r.content
            except Exception as http_e:
                raise RuntimeError(f"TTS synthesis failed (direct: {e}, HTTP: {http_e})")
            raise RuntimeError(f"TTS synthesis failed: {e}")


async def decode_accept(rec: KaldiRecognizer, chunk: bytes) -> bool:
    if DECODE_IN_THREAD:
        return await asyncio.to_thread(rec.AcceptWaveform, chunk)
    return rec.AcceptWaveform(chunk)


async def call_tts_api(text: str) -> str:
    """–í—ã–∑—ã–≤–∞–µ—Ç TTS API –¥–ª—è –æ–∑–≤—É—á–∫–∏ —Ç–µ–∫—Å—Ç–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç base64 WAV bytes"""
    try:
        import base64

        tts_url = "http://localhost:8000/tts_wav"
        payload = {
            "text": text,
            "model": "silero_ru",
            "voice": "eugene",
            "speed": 1.05,  # –ù–µ–º–Ω–æ–≥–æ –±—ã—Å—Ç—Ä–µ–µ –¥–ª—è realtime
            "emotion": "neutral",
            "pause_between_sentences": 0.12  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–∞—É–∑–∞
        }

        async with httpx.AsyncClient(timeout=30.0) as client:  # –£–º–µ–Ω—å—à–µ–Ω —Ç–∞–π–º–∞—É—Ç
            response = await client.post(tts_url, json=payload)
            if response.status_code == 200:
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º base64 encoded WAV bytes
                wav_bytes = response.content
                wav_base64 = base64.b64encode(wav_bytes).decode('utf-8')
                return f"data:audio/wav;base64,{wav_base64}"
            else:
                return f"–û—à–∏–±–∫–∞ TTS: {response.status_code}"
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ TTS API: {str(e)}"


def should_restart_llm(new_text: str, old_text: str) -> bool:
    """–≠–≤—Ä–∏—Å—Ç–∏–∫–∞: –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞—Ç—å LLM –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞"""
    new_text = (new_text or "").strip()
    old_text = (old_text or "").strip()
    if not old_text:
        return True
    if new_text == old_text:
        return False

    # 1) —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ä–æ—Å—Ç –¥–ª–∏–Ω—ã (>30%)
    if len(new_text) > int(len(old_text) * 1.3):
        return True

    # 2) –µ—Å–ª–∏ –Ω–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ —Å–∏–ª—å–Ω–æ "–ø–µ—Ä–µ—Å—Ç—Ä–æ–∏–ª–∞—Å—å"
    # –æ–±—â–∏–π –ø—Ä–µ—Ñ–∏–∫—Å –º–µ–Ω—å—à–µ –ø–æ–ª–æ–≤–∏–Ω—ã —Å—Ç–∞—Ä–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
    common = 0
    for a, b in zip(new_text, old_text):
        if a == b:
            common += 1
        else:
            break
    if common < max(1, len(old_text) // 2):
        return True

    return False

# ---------- –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π endpointing: —Ñ—É–Ω–∫—Ü–∏–∏ ----------

def clamp(v: float, lo: float, hi: float) -> float:
    return lo if v < lo else hi if v > hi else v

def update_pause_ema(pause_ema_ms: float, pause_ms: float, alpha: float) -> float:
    # —É—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ "–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ" –ø–∞—É–∑—ã (–∑–∞–ø–∏–Ω–∫–∏), –Ω–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ
    if pause_ms <= 800:
        return pause_ema_ms * (1 - alpha) + pause_ms * alpha
    return pause_ema_ms

def compute_adaptive_thresholds(text: str, wps: float, pause_ema: float) -> tuple[int, int, int]:
    """–†–∞—Å—á–µ—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤ –¥–ª—è FSM endpointing"""
    wc = len(text.strip().split())

    # –ë–∞–∑–æ–≤—ã–µ –ø–æ—Ä–æ–≥–∏ –æ—Ç —Ç–∏–ø–∏—á–Ω–æ–π –≤–Ω—É—Ç—Ä–∏–ø—Ä–µ–¥–ª–æ–∂–µ–Ω—á–µ—Å–∫–æ–π –ø–∞—É–∑—ã
    tent = max(int(pause_ema * 1.2), 300)
    confirm = max(int(pause_ema * 2.5), 900)
    final = confirm + 500

    # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è –ø–æ –¥–ª–∏–Ω–µ —Ñ—Ä–∞–∑—ã
    if wc < 4:
        confirm += 200
        final += 300

    # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –∫–æ–Ω—Ü–æ–≤–∫–∏
    if not is_good_end(text):
        confirm += 300

    # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è –ø–æ —Å–∫–æ—Ä–æ—Å—Ç–∏ —Ä–µ—á–∏
    if wps > 2.5:
        confirm += 100

    return tent, confirm, final

def compute_thresholds(pause_ema_ms: float, tentative_min: int, confirm_min: int, confirm_max: int) -> tuple[int, int]:
    """–£—Å—Ç–∞—Ä–µ–≤—à–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
    tentative = int(clamp(pause_ema_ms * 1.3, tentative_min, 650))
    confirm = int(clamp(pause_ema_ms * 3.0, confirm_min, confirm_max))
    return tentative, confirm

CONTINUE_WORDS = {
    "—á—Ç–æ","–∫–æ—Ç–æ—Ä—ã–π","–∫–æ—Ç–æ—Ä–∞—è","–∫–æ—Ç–æ—Ä—ã–µ","—á—Ç–æ–±—ã","–ø–æ—Ç–æ–º—É","–ø–æ—Ç–æ–º—É —á—Ç–æ",
    "–µ—Å–ª–∏","–∫–æ–≥–¥–∞","–ø–æ—á–µ–º—É","–∑–∞—á–µ–º","–∫–∞–∫","–≥–¥–µ","–∫—É–¥–∞","–æ—Ç–∫—É–¥–∞",
    "–∏","–∞","–Ω–æ","–∏–ª–∏","–ª–∏","—Ç–æ","—ç—Ç–æ","–≤–æ—Ç"
}
FILLERS = {"—ç","—ç–º","–Ω—É","—Ç–∏–ø–∞","–∫–æ—Ä–æ—á–µ","–∑–Ω–∞—á–∏—Ç","–º–º"}

# –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞—Ä–∏ –¥–ª—è continuation penalty
# –≠–≤—Ä–∏—Å—Ç–∏–∫–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–ª–æ—Ö–∏—Ö –∫–æ–Ω—Ü–æ–≤–æ–∫ —Ñ—Ä–∞–∑
BAD_ENDINGS = {
    "–∏", "–∞", "–Ω–æ", "–∏–ª–∏", "—á—Ç–æ", "–µ—Å–ª–∏", "—Ç–æ", "–∫–æ—Ç–æ—Ä—ã–π", "–∫–æ—Ç–æ—Ä–∞—è", "–∫–æ—Ç–æ—Ä—ã–µ",
    "—á—Ç–æ–±—ã", "–ø–æ—Ç–æ–º—É", "—Ç–∞–∫–∂–µ", "–ª–∏–±–æ", "–≤–æ—Ç", "—ç—Ç–æ", "—Ç–∞–∫", "–∫–∞–∫", "–≥–¥–µ", "–∫—É–¥–∞",
    "–æ—Ç–∫—É–¥–∞", "–∑–∞—á–µ–º", "–ø–æ—á–µ–º—É", "–∫–æ–≥–¥–∞", "—Ç–æ–≥–¥–∞", "–∑–¥–µ—Å—å", "—Ç–∞–º", "—Ç—É—Ç"
}

def is_good_end(text: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∫–æ–Ω–µ—Ü —Ñ—Ä–∞–∑—ã —Ö–æ—Ä–æ—à–∏–º –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è"""
    words = text.strip().lower().split()
    if len(words) < 3:
        return False
    return words[-1] not in BAD_ENDINGS

def common_prefix_len(a: str, b: str) -> int:
    """–î–ª–∏–Ω–∞ –æ–±—â–µ–≥–æ –ø—Ä–µ—Ñ–∏–∫—Å–∞ –¥–≤—É—Ö —Å—Ç—Ä–æ–∫"""
    n = 0
    for x, y in zip(a, b):
        if x == y:
            n += 1
        else:
            break
    return n

def is_tail_jitter(new: str, old: str, max_tail: int = 3) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ jitter'–æ–º –Ω–∞ —Ö–≤–æ—Å—Ç–µ"""
    new = (new or "").strip()
    old = (old or "").strip()
    if not old or not new or new == old:
        return False
    cp = common_prefix_len(new, old)
    tail_new = len(new) - cp
    tail_old = len(old) - cp
    return max(tail_new, tail_old) <= max_tail

def update_wps_ema(wps_ema: float, prev_words: int, new_words: int, dt_ms: int, alpha: float = 0.2) -> float:
    """–û–±–Ω–æ–≤–ª—è–µ—Ç EMA —Å–∫–æ—Ä–æ—Å—Ç–∏ —Ä–µ—á–∏ (—Å–ª–æ–≤/—Å–µ–∫)"""
    if dt_ms <= 0:
        return wps_ema
    dw = max(0, new_words - prev_words)
    inst = (dw * 1000.0) / dt_ms
    if inst <= 0:
        return wps_ema
    return wps_ema * (1 - alpha) + inst * alpha

def continuation_penalty_ms(text: str) -> int:
    """–®—Ç—Ä–∞—Ñ –Ω–∞ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –ø–æ –ª–µ–∫—Å–∏—á–µ—Å–∫–æ–º—É –∫–æ–Ω—Ç–µ–∫—Å—Ç—É"""
    w = last_word(text)
    if not w:
        return 0
    # –∂—ë—Å—Ç–∫–∏–π —à—Ç—Ä–∞—Ñ –∑–∞ —è–≤–Ω–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ
    if w in CONJ or w in PREPOSITIONS:
        return 450
    if w in PARTICLES or w in FILLERS:
        return 300
    # –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞ –Ω–∞ –∫–æ–Ω—Ü–µ
    if len(w) <= 2:
        return 250
    # –æ–±—Ä—ã–≤ –Ω–∞ —Ü–∏—Ñ—Ä–µ/—Å–æ–∫—Ä–∞—â–µ–Ω–∏–∏ —á–∞—Å—Ç–æ –Ω–µ –∫–æ–Ω–µ—Ü
    if w.isdigit():
        return 300
    return 0

def last_word(text: str) -> str:
    t = (text or "").strip().lower()
    if not t:
        return ""
    parts = t.split()
    return parts[-1] if parts else ""

def need_stricter_confirm(text: str) -> bool:
    w = last_word(text)
    return (w in CONTINUE_WORDS) or (w in FILLERS)

async def handler(ws: WebSocketServerProtocol):
    print("[HANDLER] –ù–æ–≤–æ–µ WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ")

    # –°–æ—Å—Ç–æ—è–Ω–∏–µ WebSocket –∏ –æ—á–µ—Ä–µ–¥–Ω–æ—Å—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
    ws_send_lock = asyncio.Lock()
    tts_sending = False  # –§–ª–∞–≥ –∞–∫—Ç–∏–≤–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏ TTS —Å–µ—Å—Å–∏–∏ (–æ–∫–Ω–æ –º–µ–∂–¥—É tts_start –∏ tts_end)

    # Voice Protocol State Machine
    voice_state = VoiceState.IDLE
    handshake_done = False  # –§–ª–∞–≥ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è handshake (–ø–æ–ª—É—á–µ–Ω config)

    async def ws_send(message: Union[str, bytes]):
        """–ï–¥–∏–Ω—ã–π –º–µ—Ç–æ–¥ –æ—Ç–ø—Ä–∞–≤–∫–∏ –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏–∏ –ø–æ—Ä—è–¥–∫–∞"""
        async with ws_send_lock:
            await ws.send(message)

    async def safe_send_locked(payload: dict):
        """–ü–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ WebSocket —Å–æ–æ–±—â–µ–Ω–∏–π (JSON)"""
        msg_type = payload.get('type') or payload.get('event') or 'unknown'
        print(f"[WS] ‚Üí JSON {msg_type}")
        data = json.dumps(payload, ensure_ascii=False)
        await ws_send(data)

    def proto_violation(msg: str):
        """Log protocol violation for debugging"""
        print(f"[PROTO VIOLATION] {msg}")

    async def send_audio_binary(u_id: int, wav_bytes: bytes):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –∞—É–¥–∏–æ –±–∏–Ω–∞—Ä–Ω—ã–º —Ñ—Ä–µ–π–º–æ–º –≤–º–µ—Å—Ç–æ base64"""
        if voice_state != VoiceState.ASSISTANT_TTS:
            proto_violation(f"Audio chunk sent while not in ASSISTANT_TTS state (u_id={u_id})")
            return

        if not tts_sending:
            proto_violation(f"Audio chunk sent outside tts window (u_id={u_id})")
            return

        print(f"[WS] ‚Üí BIN audio {len(wav_bytes)} bytes")
        header = struct.pack("<4sIHI", AUDIO_MAGIC, u_id, MIME_WAV, len(wav_bytes))
        await ws_send(header + wav_bytes)

    # Origin check (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    if ALLOWED_ORIGINS:
        try:
            request_headers_origin = ws.request_headers if hasattr(ws, 'request_headers') else ws.request.headers
            origin = request_headers_origin.get("Origin")
        except AttributeError:
            origin = None
        if not origin or origin not in ALLOWED_ORIGINS:
            await ws.close(code=1008, reason="Origin not allowed")
            return

    # JWT Token –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ—Ñ–∏–ª—è –∞–≥–µ–Ω—Ç–∞
    # –ß–∏—Ç–∞–µ–º —Ç–æ–∫–µ–Ω –∏–∑ Authorization header
    # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–Ω—ã—Ö –≤–µ—Ä—Å–∏–π websockets
    try:
        request_headers = ws.request_headers if hasattr(ws, 'request_headers') else ws.request.headers
    except AttributeError:
        request_headers = {}

    auth_header = request_headers.get("Authorization")

    token = None
    if auth_header and auth_header.startswith("Bearer "):
        token = auth_header.replace("Bearer ", "").strip()

    # FALLBACK: token –∏–∑ query (?token=...)
    if not token:
        try:
            # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–Ω—ã—Ö –≤–µ—Ä—Å–∏–π websockets
            ws_path = ws.path if hasattr(ws, 'path') else (ws.request.path if hasattr(ws, 'request') else '/unknown')
            parsed = urlparse(ws_path)  # —Å–æ–¥–µ—Ä–∂–∏—Ç query
            qs = parse_qs(parsed.query)
            token = (qs.get("token") or qs.get("access_token") or qs.get("jwt") or [None])[0]
        except Exception as e:
            print(f"[AUTH] Error parsing query: {e}")
            token = None

    # –õ–æ–∫–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º: –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é
    if DISABLE_AUTH or LOCAL_MODE:
        print("[AUTH] üîì Local mode: authentication disabled")
        agent_id = "assistant"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –∞–≥–µ–Ω—Ç
        session_id = f"local-{int(time.time() * 1000)}"
        payload = {"agent": agent_id, "sub": session_id}
    else:
        # Production —Ä–µ–∂–∏–º: —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ç–æ–∫–µ–Ω
        if not token:
            print("[AUTH] Missing token (Authorization/query), closing connection")
            try:
                ws_path = ws.path if hasattr(ws, 'path') else (ws.request.path if hasattr(ws, 'request') else '/unknown')
                print(f"[AUTH] Debug: ws.path = {ws_path}")
            except Exception as e:
                print(f"[AUTH] Debug: Cannot access path: {e}")
            print(f"[AUTH] Debug: Authorization header = {auth_header}")
            await ws.close(code=4001, reason="Missing token")
            return

        try:
            payload = verify_ws_token(token)
        except Exception as e:
            print(f"[AUTH] Invalid token: {e}")
            await ws.close(code=4001, reason="Invalid token")
            return

        agent_id = payload.get("agent")
        if not agent_id or agent_id not in AGENTS:
            print(f"[AUTH] Unknown agent: {agent_id}")
            await ws.close(code=1008, reason="Unknown agent")
            return

        session_id = payload.get("sub")

    agent = AGENTS[agent_id]

    print(f"[AUTH] ‚úÖ Authenticated: session={session_id}, agent={agent_id}")

    # State transition: authenticated, ready for user input
    voice_state = VoiceState.USER_SPEAKING

    # –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –°–ï–°–°–ò–ò –î–õ–Ø –•–†–ê–ù–ï–ù–ò–Ø –ö–û–ù–¢–ï–ö–°–¢–ê
    session = SESSIONS.get(session_id)
    if not session:
        session = SessionState(session_id=session_id, agent_id=agent_id)
        SESSIONS[session_id] = session
        print(f"[SESSION:{session_id}] Created new session with agent {agent_id}")
    else:
        print(f"[SESSION:{session_id}] Resumed existing session with {len(session.turns)} turns")

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ LLM –¥–ª—è —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏
    llm_model = agent.get("model") or agent.get("llm_model", "deepseek-chat")
    llm_temp = agent.get("temperature", 0.4)
    llm_max_tokens = agent.get("max_tokens", 220)
    system_prompt = agent.get("system_prompt", "–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.")

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ TTS –¥–ª—è —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏
    tts_settings = TTSSettings(
        model=agent.get("tts_model", "silero_ru"),
        voice=agent.get("tts_voice", "eugene"),
        speed=agent.get("tts_speed", 1.05),
        emotion=agent.get("tts_emotion", "neutral"),
        pause=agent.get("tts_pause", 0.12),
        timeout=TTS_TIMEOUT,
    )

    print(f"[AGENT] Profile: model={llm_model}, temp={llm_temp}, max_tokens={llm_max_tokens}")
    print(f"[AGENT] TTS: model={tts_settings.model}, voice={tts_settings.voice}, speed={tts_settings.speed}")

    # HELPER FUNCTIONS –î–õ–Ø –û–ë–†–ê–ë–û–¢–ö–ò FINAL TEXT –ò –ó–ê–©–ò–¢–´ –û–¢ –≠–•–ê
    def _norm(s: str) -> str:
        return " ".join((s or "").lower().strip().split())

    def _is_echo_like(text: str, session: SessionState) -> bool:
        # –ø—Ä–æ—Å—Ç–∞—è –∑–∞—â–∏—Ç–∞: –µ—Å–ª–∏ final —Å–ª–∏—à–∫–æ–º –ø–æ—Ö–æ–∂ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π assistant
        u = _norm(text)
        if len(u) < 8:
            return False
        last_a = ""
        for t in reversed(session.turns):
            if t.role == "assistant" and t.text:
                last_a = _norm(t.text)
                break
        if not last_a:
            return False
        # –≥—Ä—É–±—ã–π similarity: —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –ø—Ä–µ—Ñ–∏–∫—Å—É/–ø–æ–¥—Å—Ç—Ä–æ–∫–µ
        return (u in last_a) or (last_a in u) or (u[:40] == last_a[:40])

    async def handle_final_text(final_text: str, reason: str):
        nonlocal ack_sent_for_turn, llm_started, current_llm_input, active_output_u, tts_allowed_u

        final_text = (final_text or "").strip()
        if not final_text:
            return

        session = SESSIONS.get(session_id)
        if session:
            # 1) –∞–Ω—Ç–∏-—ç—Ö–æ: –µ—Å–ª–∏ —Å–µ–π—á–∞—Å —à—ë–ª TTS –∏–ª–∏ –æ—á–µ–Ω—å –±–ª–∏–∑–∫–æ –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É —á–∞–Ω–∫—É ‚Äî –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ–º final –∫–∞–∫ user
            if tts_playing or (now_ms() - last_tts_chunk_ms) < BARGE_IN_IGNORE_AFTER_TTS_MS:
                print(f"[ECHO] drop final during/after tts: '{final_text[:80]}...'")
                return

            # 2) –∞–Ω—Ç–∏-—ç—Ö–æ –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é
            if _is_echo_like(final_text, session):
                print(f"[ECHO] drop echo-like final: '{final_text[:80]}...'")
                return

            # 3) —Å–æ—Ö—Ä–∞–Ω—è–µ–º user turn (–í–ê–ñ–ù–û: –¥–µ–ª–∞—Ç—å –∏–º–µ–Ω–Ω–æ —Ç—É—Ç)
            session.add_turn("user", final_text)

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ –≤ Voice Control
            event = normalize_event(
                event_type="final",
                role="user",
                text=final_text,
            )
            if event:
                await push_event_to_voice_control(session_id, event)
                print(f"[SESSION:{session_id}] Added user turn, total turns: {len(session.turns)}")
            else:
                print(f"[EVENT] Dropped invalid user event: text='{final_text[:50]}...'")

        # 4) –∑–∞–ø—É—Å–∫/—Ä–µ—Å—Ç–∞—Ä—Ç LLM
        print(f"[TTS] enqueue: '{final_text[:50]}...'")
        if not llm_started:
            play_ack = not ack_sent_for_turn
            await start_or_restart_llm(final_text, reason=reason, play_ack=play_ack, allow_tts=True)
            if play_ack:
                ack_sent_for_turn = True
        elif should_restart_llm(final_text, current_llm_input):
            await start_or_restart_llm(final_text, reason=f"{reason}_restart", play_ack=False, allow_tts=True)
        else:
            # LLM —É–∂–µ –∏–¥—ë—Ç, –ø—Ä–æ—Å—Ç–æ —Ä–∞–∑—Ä–µ—à–∞–µ–º –æ–∑–≤—É—á–∫—É
            if tts_allowed_u == 0 and active_output_u != 0:
                tts_allowed_u = active_output_u

    sample_rate = DEFAULT_SAMPLE_RATE
    phrase_list = None
    words = False

    rec = build_recognizer(sample_rate, phrase_list=phrase_list, words=words)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è VAD
    vad = webrtcvad.Vad(VAD_MODE)

    # –î–æ–±–∞–≤–ª—è–µ–º soft_reset –º–µ—Ç–æ–¥ –¥–ª—è –ø–ª–∞–≤–Ω–æ–π —Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
    def vad_soft_reset():
        """
        –ú—è–≥–∫–∏–π —Å–±—Ä–æ—Å VAD: —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é, –Ω–æ —Å–±—Ä–∞—Å—ã–≤–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å—á–µ—Ç—á–∏–∫–∏.
        –ù–µ —Ç—Ä–µ–±—É–µ—Ç –Ω–æ–≤–æ–π –¥–ª–∏–Ω–Ω–æ–π —Ç–∏—à–∏–Ω—ã –¥–ª—è —Å—Ç–∞—Ä—Ç–∞ –¥–µ—Ç–µ–∫—Ç–∞ —Ä–µ—á–∏.
        """
        # webrtcvad –Ω–µ –∏–º–µ–µ—Ç –ø—É–±–ª–∏—á–Ω–æ–≥–æ API –¥–ª—è soft reset
        # –ø–æ—ç—Ç–æ–º—É –ø—Ä–æ—Å—Ç–æ –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º - VAD –ø—Ä–æ–¥–æ–ª–∂–∏—Ç —Ä–∞–±–æ—Ç—É —Å —Ç–µ–∫—É—â–∏–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º
        pass

    vad.soft_reset = vad_soft_reset

    fb = frame_bytes(sample_rate, FRAME_MS)
    audio_buf = bytearray()

    # –°–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è VAD –∏ endpointing
    last_voice_ms = now_ms()
    last_partial = ""
    last_partial_change_ms = now_ms()
    last_partial_sent_ms = 0
    early_endpoint_fired = False

    # –°–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è turn –∏ ACK
    turn_id = 0
    ack_sent_for_turn = False
    pause_gate_open = True  # gate –¥–ª—è —Ç—Ä–∏–≥–≥–µ—Ä–∞ —Å—Ç–∞—Ä—Ç–∞/—Ä–µ—Å—Ç–∞—Ä—Ç–∞ –ø–æ –ø–∞—É–∑–µ
    last_restart_ms = 0

    # ASR mute –≤–æ –≤—Ä–µ–º—è TTS
    asr_enabled = True
    asr_warming_up = False
    ASR_WARMUP_MS = 200  # 200ms –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è turn-taking
    asr_warmup_deadline = 0.0

    # –°–æ—Å—Ç–æ—è–Ω–∏–µ LLM –∫–æ–Ω–≤–µ–π–µ—Ä–∞
    utterance_id = 0
    current_llm_task: asyncio.Task | None = None
    llm_started = False
    current_llm_input = ""
    llm_started_at_ms = 0
    llm_first_token_at_ms = 0

    # TTS –∫–æ–Ω–≤–µ–π–µ—Ä
    tts = TTSBackend()
    print("[INIT] –ù–∞—á–∏–Ω–∞–µ–º warmup ACK —Ñ—Ä–∞–∑...")
    await tts.warmup_ack()  # –ü—Ä–æ–≥—Ä–µ–≤–∞–µ–º ACK
    print("[INIT] Warmup ACK –∑–∞–≤–µ—Ä—à–µ–Ω")

    # –û—á–µ—Ä–µ–¥—å –æ—Ç LLM –∫ TTS
    llm_to_tts_q: asyncio.Queue[tuple[int, str]] = asyncio.Queue(maxsize=5000)
    # tuple: (utterance_id, token_or_marker)
    # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ "" - —Å–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è

    tts_task: asyncio.Task | None = None

    # --- Barge-in config ---
    BARGE_IN_ENABLED = os.getenv("BARGE_IN_ENABLED", "1") == "1"
    BARGE_IN_MIN_VOICE_MS = int(os.getenv("BARGE_IN_MIN_VOICE_MS", "1000"))   # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–æ 1 —Å–µ–∫ –¥–ª—è —Ç–µ—Å—Ç–∞
    BARGE_IN_COOLDOWN_MS = int(os.getenv("BARGE_IN_COOLDOWN_MS", "2000"))    # –£–≤–µ–ª–∏—á–µ–Ω cooldown
    BARGE_IN_IGNORE_AFTER_TTS_MS = int(os.getenv("BARGE_IN_IGNORE_AFTER_TTS_MS", "500"))  # –£–≤–µ–ª–∏—á–µ–Ω–æ
    BARGE_IN_ARM_SILENCE_MS = int(os.getenv("BARGE_IN_ARM_SILENCE_MS", "1000"))  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–æ 1 —Å–µ–∫

    # Endpointing –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    TENTATIVE_PAUSE_MIN_MS = int(os.getenv("TENTATIVE_PAUSE_MIN_MS", "350"))
    CONFIRM_PAUSE_MIN_MS = int(os.getenv("CONFIRM_PAUSE_MIN_MS", "1100"))
    CONFIRM_PAUSE_MAX_MS = int(os.getenv("CONFIRM_PAUSE_MAX_MS", "1700"))

    PAUSE_EMA_ALPHA = float(os.getenv("PAUSE_EMA_ALPHA", "0.15"))  # —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ

    # --- Output state ---
    active_output_u = 0          # utterance_id, –∫–æ—Ç–æ—Ä—ã–π —Å–µ–π—á–∞—Å –æ–∑–≤—É—á–∏–≤–∞–µ—Ç—Å—è/–≥–µ–Ω–µ—Ä–∏—Ç—Å—è
    output_active = False        # –∏–¥—ë—Ç –æ—Ç–≤–µ—Ç (LLM/TTS)
    tts_epoch = 0                # –≤–µ—Ä—Å–∏—è –ø–æ—Ç–æ–∫–∞ TTS, —á—Ç–æ–±—ã –º–≥–Ω–æ–≤–µ–Ω–Ω–æ "–æ–±–µ—Å—Ü–µ–Ω–∏–≤–∞—Ç—å" –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø–æ—Å–ª–µ abort

    # --- Barge-in runtime ---
    voice_run_ms = 0
    last_barge_in_ms = 0
    last_tts_chunk_ms = 0        # –∫–æ–≥–¥–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–∑ –æ—Ç–ø—Ä–∞–≤–∏–ª–∏ –∞—É–¥–∏–æ (ACK/—á–∞–Ω–∫)

    # --- Barge-in arming state ---
    tts_playing = False          # —Å–µ—Ä–≤–µ—Ä —Å—á–∏—Ç–∞–µ—Ç, —á—Ç–æ —Å–µ–π—á–∞—Å –∏–¥—ë—Ç –æ–∑–≤—É—á–∫–∞
    barge_armed = False          # barge-in —Ä–∞–∑—Ä–µ—à—ë–Ω —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —Ç–∏—à–∏–Ω—ã
    silent_run_ms = 0            # —Å–∫–æ–ª—å–∫–æ –ø–æ–¥—Ä—è–¥ —Ç–∏—à–∏–Ω—ã –≤–æ –≤—Ä–µ–º—è output_active

    # --- Intelligent endpointing state ---
    pause_ema_ms = 350.0         # –∞–¥–∞–ø—Ç–∏–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ "—Ç–∏–ø–∏—á–Ω–æ–π –≤–Ω—É—Ç—Ä–∏–ø—Ä–µ–¥–ª–æ–∂–µ–Ω—á–µ—Å–∫–æ–π –ø–∞—É–∑—ã"
    silence_start_ms = 0         # –∫–æ–≥–¥–∞ –Ω–∞—á–∞–ª–∞—Å—å –ø–æ—Å–ª–µ–¥–Ω—è—è —Ç–∏—à–∏–Ω–∞
    was_voice_prev = False       # –ø—Ä–µ–¥—ã–¥—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≥–æ–ª–æ—Å–∞

    # –°–∫–æ—Ä–æ—Å—Ç—å —Ä–µ—á–∏ (WPS - words per second) –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö –ø–æ—Ä–æ–≥–æ–≤
    wps_ema = 2.2  # –Ω–∞—á–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ ~2.2 —Å–ª–æ–≤/—Å–µ–∫
    prev_wc = 0     # –ø—Ä–µ–¥—ã–¥—É—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤
    prev_wc_ts_ms = 0  # timestamp –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∏–∑–º–µ—Ä–µ–Ω–∏—è

    # FSM –¥–ª—è endpointing (–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ–∫–æ–Ω—á–∞–Ω–∏—è —Ñ—Ä–∞–∑—ã)
    endpoint_state = "listening"  # listening | tentative | confirmed | final
    endpoint_tentative_start_ms = 0  # –∫–æ–≥–¥–∞ –≤–æ—à–ª–∏ –≤ tentative
    endpoint_confirmed_start_ms = 0  # –∫–æ–≥–¥–∞ –≤–æ—à–ª–∏ –≤ confirmed

    # --- TTS gating: –Ω–µ–ª—å–∑—è –≥–æ–≤–æ—Ä–∏—Ç—å, –ø–æ–∫–∞ –Ω–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –∫–æ–Ω—Ü–∞ ---
    tts_allowed_u = 0            # utterance_id, –∫–æ—Ç–æ—Ä–æ–º—É —Ä–∞–∑—Ä–µ—à–µ–Ω–æ –æ–∑–≤—É—á–∏–≤–∞–Ω–∏–µ

    async def run_llm(u_id: int, prompt_text: str):
        """–ó–∞–ø—É—Å–∫ LLM streaming –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ utterance_id"""
        print(f"[LLM] run_llm started for utterance {u_id}: '{prompt_text}'")
        nonlocal llm_first_token_at_ms

        try:
            await safe_send_locked({"type": "nlu_start", "utterance_id": u_id, "text": prompt_text})
        except Exception as e:
            print(f"[LLM] Failed to send nlu_start (connection may be closed): {e}")
            return  # –ü—Ä–µ—Ä—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, –µ—Å–ª–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–∫—Ä—ã—Ç–æ

        session = SESSIONS.get(session_id)
        if session:
            messages = session.build_llm_messages(system_prompt, max_turns=12)
            print(f"[SESSION:{session_id}] Building messages: {len(messages)} messages, turns: {len(session.turns)}")
            # –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –±—É—Ñ–µ—Ä
            session.llm_buffers[u_id] = ""
        else:
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt_text}
            ]

        print(f"[LLM-PAYLOAD] session_id={session_id}, len(messages)={len(messages)}")

        first = True
        try:
            async for tok in openai_stream(
                None,
                messages=messages,  # <-- –∫–ª—é—á–µ–≤–æ–π –º–æ–º–µ–Ω—Ç
                model=llm_model,
                system_prompt=system_prompt,
                max_tokens=llm_max_tokens,
                temperature=llm_temp,
            ):
                if first:
                    llm_first_token_at_ms = now_ms()
                    first = False
                    await safe_send_locked({
                        "type": "metric",
                        "utterance_id": u_id,
                        "llm_first_token_ms": llm_first_token_at_ms - llm_started_at_ms
                    })

                # –∫–æ–ø–∏–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
                if session:
                    session.llm_buffers[u_id] += tok

                await safe_send_locked({"type": "llm_delta", "utterance_id": u_id, "delta": tok})

                # –ö–ª–∞–¥—ë–º —Ç–æ–∫–µ–Ω –≤ –æ—á–µ—Ä–µ–¥—å –¥–ª—è TTS (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ TTS —Ä–∞–∑—Ä–µ—à–µ–Ω –¥–ª—è —ç—Ç–æ–≥–æ utterance)
                if tts_allowed_u == u_id:
                    try:
                        await llm_to_tts_q.put((u_id, tok))
                        print(f"[LLM] –¢–æ–∫–µ–Ω '{tok}' –¥–æ–±–∞–≤–ª–µ–Ω –≤ –æ—á–µ—Ä–µ–¥—å TTS (size={llm_to_tts_q.qsize()}, allowed_u={tts_allowed_u})")
                    except asyncio.QueueFull:
                        print(f"[LLM] ‚ö†Ô∏è –û—á–µ—Ä–µ–¥—å TTS –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–æ–∫–µ–Ω '{tok}'")
                else:
                    print(f"[LLM] ‚ö†Ô∏è –¢–æ–∫–µ–Ω '{tok}' –ù–ï –¥–æ–±–∞–≤–ª–µ–Ω –≤ –æ—á–µ—Ä–µ–¥—å TTS (tts_allowed_u={tts_allowed_u}, u_id={u_id})")

        except asyncio.CancelledError:
            # –ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –æ—Ç–º–µ–Ω–∞
            raise
        except Exception as e:
            print(f"[LLM] Error in run_llm: {e}")
            try:
                await safe_send_locked({"type": "llm_error", "utterance_id": u_id, "error": str(e)})
            except Exception as send_err:
                print(f"[LLM] Failed to send error (connection closed): {send_err}")
        finally:
            # –°–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –¥–ª—è TTS
            try:
                await llm_to_tts_q.put((u_id, ""))
            except asyncio.QueueFull:
                print(f"[LLM] –û—á–µ—Ä–µ–¥—å TTS –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞, –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è")

            try:
                await safe_send_locked({"type": "llm_end", "utterance_id": u_id})
            except Exception as send_err:
                print(f"[LLM] Failed to send llm_end (connection closed): {send_err}")

    async def start_or_restart_llm(new_text: str, reason: str, play_ack: bool = False, allow_tts: bool = False):
        nonlocal utterance_id, current_llm_task, llm_started, current_llm_input, llm_started_at_ms, llm_first_token_at_ms
        nonlocal active_output_u, output_active, tts_epoch, last_tts_chunk_ms, tts_playing, tts_allowed_u
        nonlocal barge_armed, silent_run_ms, voice_run_ms, tts_sending, voice_state

        prev_u = active_output_u  # —á—Ç–æ —Å–µ–π—á–∞—Å –∏–≥—Ä–∞–µ—Ç

        # –Ω–æ–≤—ã–π –æ—Ç–≤–µ—Ç ‚Üí barge-in –Ω–µ –∞—Ä–º–∏–º, –ø–æ–∫–∞ –Ω–µ —É–≤–∏–¥–∏–º —Ç–∏—à–∏–Ω—É
        barge_armed = False
        silent_run_ms = 0
        voice_run_ms = 0
        tts_playing = False

        utterance_id += 1
        u_id = utterance_id

        # —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ TTS
        if allow_tts:
            tts_allowed_u = u_id
            print(f"[LLM] TTS allowed for utterance {u_id}")
        else:
            tts_allowed_u = 0
            print(f"[LLM] TTS NOT allowed for utterance {u_id}")

        # –æ—Ç–º–µ–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é LLM –∑–∞–¥–∞—á—É
        if current_llm_task and not current_llm_task.done():
            current_llm_task.cancel()
            if prev_u:
                await safe_send_locked({"type": "abort", "scope": "llm", "reason": reason, "utterance_id": prev_u})

        # –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–µ –∞—É–¥–∏–æ (–í–ê–ñ–ù–û: prev_u)
        if prev_u:
            await safe_send_locked({"type": "abort", "scope": "tts", "reason": reason, "utterance_id": prev_u})

        # –æ–±–µ—Å—Ü–µ–Ω–∏–≤–∞–µ–º —Ç–µ–∫—É—â–∏–µ –æ—Ç–ø—Ä–∞–≤–∫–∏ TTS
        tts_epoch += 1

        # —á–∏—Å—Ç–∏–º –æ—á–µ—Ä–µ–¥—å TTS
        while not llm_to_tts_q.empty():
            try:
                llm_to_tts_q.get_nowait()
            except asyncio.QueueEmpty:
                break

        # –∞–∫—Ç–∏–≤–∏—Ä—É–µ–º –Ω–æ–≤—ã–π output
        active_output_u = u_id
        output_active = True

        current_llm_input = new_text
        llm_started = True
        llm_started_at_ms = now_ms()
        llm_first_token_at_ms = 0

        await safe_send_locked({
            "type": "llm_start",
            "utterance_id": u_id,
            "text": current_llm_input
        })

        # ACK –∑–≤—É–∫ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –ò —Ä–∞–∑—Ä–µ—à–µ–Ω–æ –æ–∑–≤—É—á–∏–≤–∞–Ω–∏–µ
        if play_ack and allow_tts:
            if tts_sending:
                proto_violation("Attempted ACK while TTS window is active")
            elif voice_state == VoiceState.ASSISTANT_TTS:
                proto_violation("Attempted ACK while in ASSISTANT_TTS state")
            else:
                # State transition: start ACK TTS
                voice_state = VoiceState.ASSISTANT_TTS
                tts_sending = True

                ack_text, ack_wav = tts.get_random_ack_wav()
                if ack_wav is None:
                    # –ï—Å–ª–∏ –∫—ç—à –Ω–µ –≥–æ—Ç–æ–≤, —Å–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º –Ω–∞ –ª–µ—Ç—É
                    ack_text = tts.get_random_ack_text()
                    ack_wav = await call_with_retry(lambda: tts.synthesize_wav(ack_text, settings=tts_settings), retries=1)

                # –ñ—ë—Å—Ç–∫–æ –æ—Ç–∫—Ä—ã–≤–∞–µ–º –æ–∫–Ω–æ TTS –¥–ª—è ACK
                print(f"[WS] ‚Üí JSON tts_start (ack)")
                await safe_send_locked({
                    "type": "tts_start",
                    "utterance_id": u_id,
                    "mime": "audio/wav",
                    "note": "ack"
                })

                await send_audio_binary(u_id, ack_wav)

                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º tts_end –¥–ª—è ACK, —á—Ç–æ–±—ã –∑–∞–∫—Ä—ã—Ç—å —ç—Ç–æ—Ç –º–∏–Ω–∏-—Å–µ–∞–Ω—Å
                # –û—Å–Ω–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç LLM –æ—Ç–∫—Ä–æ–µ—Ç —Å–≤–æ–π tts_start –≤ run_tts
                print(f"[WS] ‚Üí JSON tts_end (ack, u_id={u_id})")
                await safe_send_locked({
                    "type": "tts_end",
                    "utterance_id": u_id
                })
                
                # –ù–ï —Å–±—Ä–∞—Å—ã–≤–∞–µ–º voice_state –∑–¥–µ—Å—å, run_tts —Å–∞–º —É—Å—Ç–∞–Ω–æ–≤–∏—Ç ASSISTANT_TTS
                # voice_state = VoiceState.USER_SPEAKING # –≠—Ç–∞ —Å—Ç—Ä–æ–∫–∞ –≤—ã–∑—ã–≤–∞–µ—Ç race condition!
                tts_sending = False  # ACK —Å–µ—Å—Å–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞, run_tts –æ—Ç–∫—Ä–æ–µ—Ç –Ω–æ–≤—É—é
            tts_playing = True
            last_tts_chunk_ms = now_ms()  # anti-echo –æ–∫–Ω–æ
            print(f"[ACK] –û—Ç–ø—Ä–∞–≤–ª–µ–Ω ACK '{ack_text}' –¥–ª—è utterance {u_id}")

        current_llm_task = asyncio.create_task(run_llm(u_id, current_llm_input))

    async def abort_output(reason: str):
        nonlocal output_active, active_output_u, tts_epoch
        nonlocal voice_run_ms, last_barge_in_ms
        nonlocal tts_playing, barge_armed, silent_run_ms
        nonlocal current_llm_task

        if not output_active or active_output_u == 0:
            return

        u = active_output_u
        output_active = False
        active_output_u = 0
        tts_epoch += 1           # –ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ run_tts –ø–µ—Ä–µ—Å—Ç–∞–Ω–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –∞—É–¥–∏–æ

        # —Å–±—Ä–æ—Å barge-in state, –∏–Ω–∞—á–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –º–æ–∂–µ—Ç "–∑–∞–ª–∏–ø–Ω—É—Ç—å"
        tts_playing = False
        tts_sending = False
        barge_armed = False

        # State transition: abort resets to idle/speaking
        if voice_state == VoiceState.ASSISTANT_TTS:
            voice_state = VoiceState.USER_SPEAKING
        silent_run_ms = 0
        voice_run_ms = 0
        tts_allowed_u = 0  # —Å–±—Ä–æ—Å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –Ω–∞ TTS

        # —Å–±—Ä–æ—Å LLM —Å–æ—Å—Ç–æ—è–Ω–∏–π –ø—Ä–∏ abort
        llm_started = False
        current_llm_input = ""

        last_barge_in_ms = now_ms()

        # cancel LLM
        if current_llm_task and not current_llm_task.done():
            current_llm_task.cancel()

        # –∫–æ–º–∞–Ω–¥–∞ –∫–ª–∏–µ–Ω—Ç—É –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø—Ä–æ–∏–≥—Ä—ã–≤–∞–Ω–∏–µ
        print(f"[WS] ‚Üí JSON abort (llm)")
        await safe_send_locked({"type": "abort", "scope": "llm", "reason": reason, "utterance_id": u})
        print(f"[WS] ‚Üí JSON abort (tts)")
        await safe_send_locked({"type": "abort", "scope": "tts", "reason": reason, "utterance_id": u})

        # —á–∏—Å—Ç–∏–º –æ—á–µ—Ä–µ–¥—å, —á—Ç–æ–±—ã —Ö–≤–æ—Å—Ç—ã –Ω–µ –¥–æ–≥–æ–Ω—è–ª–∏
        while not llm_to_tts_q.empty():
            try:
                llm_to_tts_q.get_nowait()
            except asyncio.QueueEmpty:
                break

    async def run_tts():
        """
        Consumer –¥–ª—è –æ—á–µ—Ä–µ–¥–∏ LLM‚ÜíTTS.
        –ß–∏—Ç–∞–µ—Ç —Ç–æ–∫–µ–Ω—ã, —Å–æ–±–∏—Ä–∞–µ—Ç –≤ —á–∞–Ω–∫–∏ –∏ –æ–∑–≤—É—á–∏–≤–∞–µ—Ç.
        """
        print(f"[TTS] run_tts STARTED")
        nonlocal tts_epoch, active_output_u, output_active, last_tts_chunk_ms, tts_playing, tts_allowed_u
        nonlocal asr_enabled, asr_warming_up, asr_warmup_deadline, llm_started, current_llm_input, tts_sending
        nonlocal voice_state  # –ö–†–ò–¢–ò–ß–ù–û: –±–µ–∑ —ç—Ç–æ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è voice_state –Ω–µ –≤–∏–¥–Ω—ã –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ!
        current_u = -1  # –ò—Å–ø–æ–ª—å–∑—É–µ–º -1 –≤–º–µ—Å—Ç–æ 0, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ª–æ–∂–Ω—ã—Ö cleanup
        buf = ""
        local_epoch = tts_epoch

        print(f"[TTS] Consumer started with initial epoch {local_epoch}")

        while True:
            print(f"[TTS] –û–∂–∏–¥–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞ –∏–∑ –æ—á–µ—Ä–µ–¥–∏ (epoch={local_epoch}, active={active_output_u})...")
            u_id, tok = await llm_to_tts_q.get()
            print(f"[TTS] –ü–æ–ª—É—á–µ–Ω —Ç–æ–∫–µ–Ω: utterance={u_id}, token='{tok[:20]}...', queue_size={llm_to_tts_q.qsize()}")

            # –ù–æ–≤—ã–π utterance - —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –±—É—Ñ–µ—Ä –∏ –æ—Ç–∫—Ä—ã–≤–∞–µ–º –æ–∫–Ω–æ TTS
            if u_id != current_u and current_u != -1:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ current_u –±—ã–ª —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ä–∞–Ω–µ–µ
                if tts_sending:
                    # –ó–∞–≤–µ—Ä—à–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é TTS —Å–µ—Å—Å–∏—é, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ –±—ã–ª–∞ –∑–∞–∫—Ä—ã—Ç–∞
                    print(f"[WS] ‚Üí JSON tts_end (overlap cleanup, current_u={current_u})")
                    await safe_send_locked({"type": "tts_end", "utterance_id": current_u})
                    tts_sending = False

            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–æ–≤—ã–π utterance (–µ—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ –∏–ª–∏ –Ω–æ–≤—ã–π utterance)
            if u_id != current_u:
                current_u = u_id
                buf = ""
                local_epoch = tts_epoch

                # –í–°–ï–ì–î–ê –ø–æ—Å—ã–ª–∞–µ–º tts_start –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞, –¥–∞–∂–µ –µ—Å–ª–∏ –±—ã–ª ACK
                # –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥ –≥–æ—Ç–æ–≤ –ø—Ä–∏–Ω–∏–º–∞—Ç—å –Ω–æ–≤—ã–µ —á–∞–Ω–∫–∏ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                voice_state = VoiceState.ASSISTANT_TTS
                tts_sending = True
                
                print(f"[WS] ‚Üí JSON tts_start (main response, u_id={current_u})")
                await safe_send_locked({
                    "type": "tts_start",
                    "utterance_id": current_u,
                    "mime": "audio/wav"
                })

                # HARD MUTE ASR –≤–æ –≤—Ä–µ–º—è TTS
                asr_enabled = False
                asr_warming_up = False
                print(f"[ASR] Muted during TTS utterance {current_u}")

            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω—ã —Å—Ç–∞—Ä—ã—Ö utterance
            if u_id != current_u:
                print(f"[TTS] SKIP token from old utterance: u_id={u_id}, current_u={current_u}, tok='{tok[:20] if tok else 'EOF'}'")
                continue

            # –ú–∞—Ä–∫–µ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è LLM
            if tok == "":
                print(f"[TTS] ‚úÖ EOF MARKER received for utterance {current_u}, buf: '{buf}' (len={len(buf)})")
                print(f"[TTS] Starting cleanup: tts_sending={tts_sending}, voice_state={voice_state}")
                
                # –°–Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —á–∞–Ω–∫–∏ –∏–∑ –±—É—Ñ–µ—Ä–∞
                while buf.strip():
                    chunks, buf = split_for_tts(buf)
                    print(f"[TTS] –§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: —Ä–∞–∑–±–∏—Ç–æ –Ω–∞ {len(chunks)} —á–∞–Ω–∫–æ–≤, –æ—Å—Ç–∞—Ç–æ–∫: '{buf}'")
                    for chunk in chunks:
                        if len(chunk) < 10:  # –û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ —á–∞–Ω–∫–∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                            continue
                        try:
                            wav = await call_with_retry(lambda: tts.synthesize_wav(chunk, settings=tts_settings), retries=1)
                            guard_active = not output_active
                            guard_u = current_u != active_output_u
                            guard_epoch = local_epoch != tts_epoch
                            guard_tts_allowed = (tts_allowed_u != current_u)
                            if guard_active or guard_u or guard_epoch or guard_tts_allowed:
                                print(f"[TTS] –§–∏–Ω–∞–ª—å–Ω—ã–π —á–∞–Ω–∫ –ø—Ä–æ–ø—É—â–µ–Ω: active={output_active}({guard_active}), current_u={current_u} != active_u={active_output_u}({guard_u})")
                                continue
                            await safe_send_locked({
                                "type": "tts_audio",
                                "utterance_id": current_u,
                                "mime": "audio/wav"
                            })
                            tts_playing = True
                            await send_audio_binary(current_u, wav)
                            last_tts_chunk_ms = now_ms()
                            print(f"[TTS] –§–∏–Ω–∞–ª—å–Ω—ã–π —á–∞–Ω–∫ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω: '{chunk[:30]}...' ({len(wav)} bytes)")
                        except Exception as e:
                            print(f"[TTS] –û—à–∏–±–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —á–∞–Ω–∫–∞: {e}")
                    
                    # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ä–∞–∑–±–∏–µ–Ω–∏—è –æ—Å—Ç–∞–ª—Å—è –º–∞–ª–µ–Ω—å–∫–∏–π –æ—Å—Ç–∞—Ç–æ–∫, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –µ–≥–æ –∫–∞–∫ –µ—Å—Ç—å
                    if buf.strip() and len(buf.strip()) >= 10:
                        tail = buf.strip()
                        try:
                            wav = await call_with_retry(lambda: tts.synthesize_wav(tail, settings=tts_settings), retries=1)
                            guard_active = not output_active
                            guard_u = current_u != active_output_u
                            guard_epoch = local_epoch != tts_epoch
                            guard_tts_allowed = (tts_allowed_u != current_u)
                            if not (guard_active or guard_u or guard_epoch or guard_tts_allowed):
                                await safe_send_locked({
                                    "type": "tts_audio",
                                    "utterance_id": current_u,
                                    "mime": "audio/wav"
                                })
                                tts_playing = True
                                await send_audio_binary(current_u, wav)
                                last_tts_chunk_ms = now_ms()
                                print(f"[TTS] –ü–æ—Å–ª–µ–¥–Ω–∏–π –æ—Å—Ç–∞—Ç–æ–∫ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω: '{tail[:30]}...' ({len(wav)} bytes)")
                        except Exception as e:
                            print(f"[TTS] –û—à–∏–±–∫–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ—Å—Ç–∞—Ç–∫–∞: {e}")
                        buf = ""  # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏

                if current_u == active_output_u:
                    output_active = False
                    active_output_u = 0
                
                print(f"[WS] ‚Üí JSON tts_end")
                
                # –ö–†–ò–¢–ò–ß–ù–û: –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥–∏ –î–û –æ—Ç–ø—Ä–∞–≤–∫–∏ tts_end, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –≥–æ–Ω–∫–∏ —É—Å–ª–æ–≤–∏–π
                # –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –∫ –º–æ–º–µ–Ω—Ç—É –ø–æ–ª—É—á–µ–Ω–∏—è tts_end –∫–ª–∏–µ–Ω—Ç–æ–º, —Å–æ—Å—Ç–æ—è–Ω–∏–µ —É–∂–µ –æ–±–Ω–æ–≤–ª–µ–Ω–æ
                tts_playing = False
                tts_sending = False
                
                # State transition: TTS finished
                if voice_state != VoiceState.ASSISTANT_TTS:
                    proto_violation("tts_end received while not in TTS state")
                
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ IDLE, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –∂–¥–∞—Ç—å –Ω–æ–≤—É—é —Ä–µ–ø–ª–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                voice_state = VoiceState.IDLE
                print(f"[STATE] ASSISTANT_TTS ‚Üí IDLE (TTS finished for utterance {current_u})")
                
                await safe_send_locked({"type": "tts_end", "utterance_id": current_u})

                # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å Vosk, —á—Ç–æ–±—ã –æ–Ω –Ω–µ —É—á–∏—Ç—ã–≤–∞–ª —Å—Ç–∞—Ä—ã–π —à—É–º/—ç—Ö–æ
                try:
                    rec.Reset()
                    print("[ASR] Vosk recognizer reset after TTS")
                except Exception as e:
                    print(f"[ASR] Failed to reset Vosk: {e}")

                # –°–ë–†–û–° –¢–ê–ô–ú–ï–†–û–í –¢–ò–®–ò–ù–´: –∫—Ä–∞–π–Ω–µ –≤–∞–∂–Ω–æ –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞
                now_after_tts = now_ms()
                last_voice_ms = now_after_tts
                last_partial_change_ms = now_after_tts
                last_tts_chunk_ms = 0  # –ö–†–ò–¢–ò–ß–ù–û: —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Ç–∞–π–º–µ—Ä TTS, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É
                last_partial = ""
                endpoint_state = "listening"
                ack_sent_for_turn = False # –†–∞–∑—Ä–µ—à–∞–µ–º ACK –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π —Ñ—Ä–∞–∑—ã
                print("[ASR] Silence timers, TTS timer, and endpoint state reset after TTS")

                # ASR WARMUP: –º—è–≥–∫–∞—è —Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Å–ª–µ TTS
                asr_enabled = True
                asr_warming_up = True
                asr_warmup_deadline = time.time() + (ASR_WARMUP_MS / 1000.0)
                print(f"[ASR] Warmup mode after TTS utterance {current_u} (deadline: {asr_warmup_deadline:.3f})")

                # –°–û–•–†–ê–ù–ò–¢–¨ –ü–û–õ–ù–´–ô –û–¢–í–ï–¢ –ê–°–°–ò–°–¢–ï–ù–¢–ê –í –ò–°–¢–û–†–ò–Æ –°–ï–°–°–ò–ò (–°–¢–†–û–ì–û –û–î–ò–ù –†–ê–ó)
                session = SESSIONS.get(session_id)
                if session:
                    assistant_text = session.llm_buffers.pop(current_u, "").strip()
                    if assistant_text:
                        session.add_turn("assistant", assistant_text, utterance_id=current_u)

                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ –≤ Voice Control
                        event = normalize_event(
                            event_type="final",
                            role="assistant",
                            text=assistant_text,
                        )
                        if event:
                            await push_event_to_voice_control(session_id, event)
                            print(f"[SESSION:{session_id}] Saved assistant response: '{assistant_text[:50]}...'")
                            print(f"[SESSION:{session_id}] Session now has {len(session.turns)} turns total")
                        else:
                            print(f"[EVENT] Dropped invalid assistant event: text='{assistant_text[:50]}...'")
                
                # –°–ë–†–û–° —Å–æ—Å—Ç–æ—è–Ω–∏–π –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è utterance
                llm_started = False
                current_llm_input = ""
                tts_allowed_u = 0
                continue

            # –ù–æ—Ä–º–∞–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω - –¥–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
            # –§–∏–ª—å—Ç—Ä—É–µ–º –æ—á–µ–≤–∏–¥–Ω—ã–µ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Å–ª–æ–≤
            test_buf = buf + tok
            words = test_buf.split()
            filtered_words = []
            for word in words:
                # –£–±–∏—Ä–∞–µ–º —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–≤—Ç–æ—Ä—è—é—Ç—Å—è –ø–æ–¥—Ä—è–¥
                if len(filtered_words) == 0 or word != filtered_words[-1]:
                    filtered_words.append(word)
                elif word == filtered_words[-1] and len(word) > 3:  # –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–ª–æ–≤ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
                    continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª–∏–Ω–Ω—ã—Ö —Å–ª–æ–≤

            buf = ' '.join(filtered_words)
            print(f"[TTS] –ë—É—Ñ–µ—Ä –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: '{buf}' (len={len(buf)})")

            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏ –∏ –æ–∑–≤—É—á–∏–≤–∞–µ–º (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —á–∞–Ω–∫ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–æ–π)
            chunks, buf = split_for_tts(buf)
            if chunks:
                print(f"[TTS] –†–∞–∑–±–∏—Ç–æ –Ω–∞ {len(chunks)} —á–∞–Ω–∫–æ–≤, –æ—Å—Ç–∞—Ç–æ–∫: '{buf}'")
            for chunk in chunks:
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ —á–∞–Ω–∫–∏, –∫—Ä–æ–º–µ –∑–∞–≤–µ—Ä—à–∞—é—â–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
                # –°–Ω–∏–∑–∏–ª–∏ –ø–æ—Ä–æ–≥ —Å 20 –¥–æ 10 –¥–ª—è –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–π –æ–∑–≤—É—á–∫–∏ –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤
                if len(chunk) < 10 and not chunk.endswith(('.', '!', '?', '\n', ',')):
                    print(f"[TTS] –ß–∞–Ω–∫ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π, –æ—Ç–∫–ª–∞–¥—ã–≤–∞–µ–º: '{chunk}' (len={len(chunk)})")
                    buf = chunk + ' ' + buf  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ –±—É—Ñ–µ—Ä
                    continue
                try:
                    wav = await call_with_retry(lambda: tts.synthesize_wav(chunk, settings=tts_settings), retries=1)
                    guard_active = not output_active
                    guard_u = current_u != active_output_u
                    guard_epoch = local_epoch != tts_epoch
                    guard_tts_allowed = (tts_allowed_u != current_u)
                    print(f"[TTS] Guard check: active={output_active}, current_u={current_u}, active_u={active_output_u}, tts_allowed_u={tts_allowed_u}, epoch={local_epoch}/{tts_epoch}")
                    if guard_active or guard_u or guard_epoch or guard_tts_allowed:
                        # –æ—Ç–≤–µ—Ç —É–∂–µ –ø—Ä–µ—Ä–≤–∞–Ω –∏–ª–∏ —É—Å—Ç–∞—Ä–µ–ª –∏–ª–∏ TTS –Ω–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–æ
                        print(f"[TTS] ‚ùå –ß–∞–Ω–∫ –ø—Ä–æ–ø—É—â–µ–Ω: active={output_active}({guard_active}), current_u={current_u} != active_u={active_output_u}({guard_u}), local_epoch={local_epoch} != global_epoch={tts_epoch}({guard_epoch}), tts_allowed_u={tts_allowed_u}({guard_tts_allowed})")
                        continue
                    print(f"[TTS] ‚úÖ –û—Ç–ø—Ä–∞–≤–∫–∞ —á–∞–Ω–∫–∞: '{chunk[:30]}...' ({len(wav)} bytes)")
                    await safe_send_locked({
                        "type": "tts_audio",
                        "utterance_id": current_u,
                        "mime": "audio/wav"
                    })
                    tts_playing = True
                    await send_audio_binary(current_u, wav)
                    last_tts_chunk_ms = now_ms()
                    print(f"[TTS] ‚úÖ –ß–∞–Ω–∫ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω: '{chunk[:30]}...' ({len(wav)} bytes)")
                except Exception as e:
                    print(f"[TTS] –û—à–∏–±–∫–∞ —á–∞–Ω–∫–∞ '{chunk[:30]}...': {e}")
                    await safe_send_locked({
                        "type": "tts_error",
                        "utterance_id": current_u,
                        "error": f"Chunk failed: {str(e)}"
                    })

    # –ó–∞–ø—É—Å–∫–∞–µ–º TTS consumer
    if tts_task is None:
        tts_task = asyncio.create_task(run_tts())
        print("[TTS] Consumer –∑–∞–ø—É—â–µ–Ω")
    else:
        print("[TTS] Consumer —É–∂–µ –∑–∞–ø—É—â–µ–Ω")

    await safe_send_locked({
        "event": "ready",
        "sample_rate": sample_rate,
        "frame_ms": FRAME_MS,
        "vad_mode": VAD_MODE,
        "early_pause_ms": EARLY_PAUSE_MS,
        "final_pause_ms": FINAL_PAUSE_MS,
        "stable_ms": STABLE_MS
    })

    # –î–ª—è cancel –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö chat –∑–∞–ø—Ä–æ—Å–æ–≤ (legacy)
    current_chat_task: asyncio.Task | None = None

    async def run_chat(question: str):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç streaming chat —Å DeepSeek"""
        try:
            print(f"[CHAT] –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–æ–ø—Ä–æ—Å–∞: '{question}'")
            await safe_send_locked({"type": "chat_start", "question": question})
            print(f"[CHAT] –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ chat_start")

            acc = []
            token_count = 0
            async for token in openai_stream(question, model=llm_model, system_prompt=system_prompt, max_tokens=llm_max_tokens, temperature=llm_temp):
                acc.append(token)
                token_count += 1
                await safe_send_locked({"type": "chat_delta", "delta": token})

            answer = "".join(acc).strip()
            print(f"[CHAT] –ó–∞–≤–µ—Ä—à–µ–Ω–æ. –¢–æ–∫–µ–Ω–æ–≤: {token_count}, –û—Ç–≤–µ—Ç: '{answer[:100]}...'")

            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–∑–≤—É—á–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ TTS
            print(f"[TTS] –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ –æ–∑–≤—É—á–∫—É: '{answer[:50]}...'")
            audio_data = await call_tts_api(answer)
            print(f"[TTS] –ê—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã (–¥–ª–∏–Ω–∞: {len(audio_data) if audio_data else 0})")

            await safe_send_locked({"type": "chat_end", "question": question, "answer": answer, "audio_data": audio_data})
        except asyncio.CancelledError:
            print(f"[CHAT] –ó–∞–¥–∞—á–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞: '{question}'")
            # –ó–∞–¥–∞—á–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞, –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
            pass
        except Exception as e:
            print(f"[CHAT] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–æ–ø—Ä–æ—Å–∞ '{question}': {e}")
            await safe_send_locked({"type": "chat_error", "error": str(e)})

    try:
        async for msg in ws:
            # === –û–ë–†–ê–ë–û–¢–ö–ê –¢–ï–ö–°–¢–û–í–´–• –°–û–û–ë–©–ï–ù–ò–ô (JSON) ===
            if isinstance(msg, str):
                print(f"[WS] –ü–æ–ª—É—á–µ–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: {msg[:100]}..." if len(msg) > 100 else f"[WS] –ü–æ–ª—É—á–µ–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: {msg}")
                try:
                    data = json.loads(msg)
                    print(f"[WS] –†–∞—Å–ø–∞—Ä—Å–µ–Ω–æ JSON: {data}")
                except json.JSONDecodeError as e:
                    print(f"[WS] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
                    continue

                # === CONFIG HANDLER (HANDSHAKE) ===
                if "config" in data:
                    try:
                        if handshake_done:
                            # –ü–æ–≤—Ç–æ—Ä–Ω—ã–π config ‚Äî –ø—Ä–æ—Ç–æ–∫–æ–ª—å–Ω–æ–µ –Ω–∞—Ä—É—à–µ–Ω–∏–µ, –Ω–æ –Ω–µ —Ä–≤—ë–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
                            logger.warning("[PROTO] Duplicate config received, ignored")
                            await safe_send_locked({
                                "event": "warning",
                                "reason": "config_already_applied"
                            })
                            continue  # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É, –Ω–µ –∑–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ

                        cfg = data.get("config") or {}
                        print(f"[HANDSHAKE] Received config: {cfg}")

                        # --- sample_rate ---
                        requested_sr = cfg.get("sample_rate")
                        try:
                            requested_sr = int(requested_sr) if requested_sr is not None else None
                        except Exception:
                            requested_sr = None

                        new_sr = normalize_sample_rate(requested_sr)

                        if requested_sr and requested_sr != new_sr:
                            await safe_send_locked({
                                "event": "reconfigured",
                                "sample_rate": new_sr,
                                "note": "server supports pcm16 mono 16000 only"
                            })

                        # --- ASR options ---
                        words = bool(cfg.get("words", False))
                        phrase_list = cfg.get("phrase_list")

                        # --- apply settings ---
                        sample_rate = new_sr
                        fb = frame_bytes(sample_rate, FRAME_MS)

                        audio_buf.clear()
                        # webrtcvad.Vad –Ω–µ –∏–º–µ–µ—Ç –º–µ—Ç–æ–¥–∞ reset(), –Ω–æ —Å–æ—Å—Ç–æ—è–Ω–∏–µ VAD –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è handshake
                        # VAD –ø—Ä–æ–¥–æ–ª–∂–∏—Ç —Ä–∞–±–æ—Ç—É —Å —Ç–µ–∫—É—â–∏–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º
                        rec = build_recognizer(
                            sample_rate=sample_rate,
                            phrase_list=phrase_list,
                            words=words,
                        )

                        # --- handshake completed ---
                        handshake_done = True
                        asr_enabled = True

                        print("[HANDSHAKE] Config applied, sending READY")

                        await safe_send_locked({
                            "event": "ready",
                            "sample_rate": sample_rate,
                            "frame_ms": FRAME_MS,
                            "vad_mode": VAD_MODE,
                            "early_pause_ms": EARLY_PAUSE_MS,
                        })

                        print("[HANDSHAKE] READY sent")
                        continue  # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Å–ª–µ–¥—É—é—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π

                    except Exception as e:
                        print("[HANDSHAKE][FATAL]", e)
                        import traceback
                        traceback.print_exc()
                        await ws.close(code=1011, reason="config handler failed")
                        return

                # –û–ë–†–ê–ë–û–¢–ö–ê –ö–û–ú–ê–ù–î–´ –ó–ê–í–ï–†–®–ï–ù–ò–Ø –°–ï–°–°–ò–ò
                if data.get("type") == "end_session":
                    print(f"[SESSION] Received end_session command for session {session_id}")
                    session = SESSIONS.get(session_id)
                    summary = ""

                    if session and session.turns:
                        print(f"[SESSION] Building summary for session {session_id} with {len(session.turns)} turns")
                        try:
                            summary = build_session_summary(session)
                            print(f"[SESSION] Summary generated: {len(summary)} chars")
                        except Exception as e:
                            print(f"[SESSION] Error generating summary: {e}")
                            summary = f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ summary: {e}"
                    else:
                        print(f"[SESSION] No session or turns found for summary")
                        summary = "–°–µ—Å—Å–∏—è –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"

                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º summary –∫–ª–∏–µ–Ω—Ç—É
                    await safe_send_locked({
                        "type": "session_summary",
                        "session_id": session_id,
                        "agent_id": agent_id,
                        "summary": summary,
                    })

                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
                    await safe_send_locked({
                        "type": "session_end",
                        "session_id": session_id,
                    })

                    # –û—Ç–º–µ—á–∞–µ–º —Å–µ—Å—Å–∏—é –∫–∞–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—É—é (–Ω–µ —É–¥–∞–ª—è–µ–º —Å—Ä–∞–∑—É - –Ω—É–∂–µ–Ω –¥–ª—è HTTP API)
                    if session:
                        session.ended = True
                        session.ended_at_ms = now_ms()
                        session.summary = summary
                        print(f"[SESSION] Session {session_id} marked as ended (will be cleaned up by TTL)")

                    # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
                    await ws.close(code=1000, reason="client_end")
                    return


                # reset: —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—É—â—É—é —Ñ—Ä–∞–∑—É –∏ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å
                if data.get("reset") == 1:
                    final_json = json.loads(rec.FinalResult())
                    final_text = (final_json.get("text") or "").strip()
                    if final_text:  # –ù–ï –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—É—Å—Ç—ã–µ final
                        await safe_send_locked({"type": "final", **final_json})

                        # State transition: user finished speaking, starting LLM
                        if voice_state == VoiceState.USER_SPEAKING:
                            voice_state = VoiceState.IDLE  # User input complete, waiting for LLM

                    # –ó–ê–ü–£–°–ö LLM –ü–û –§–ò–ù–ê–õ–¨–ù–û–ú–£ –†–ï–ó–£–õ–¨–¢–ê–¢–£ ASR
                    await handle_final_text(final_json.get("text"), reason="final_reset")

                    # –ù–æ–≤–∞—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è —Ä–µ–ø–ª–∏–∫–∞ - —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è turn
                    turn_id += 1
                    ack_sent_for_turn = False
                    llm_started = False
                    current_llm_input = ""
                    pause_gate_open = True

                    # –°–±—Ä–æ—Å WPS —Å–æ—Å—Ç–æ—è–Ω–∏–π –¥–ª—è –Ω–æ–≤–æ–π —Ä–µ–ø–ª–∏–∫–∏
                    wps_ema = 2.2
                    prev_wc = 0
                    prev_wc_ts_ms = 0
                    rec = build_recognizer(sample_rate, phrase_list=phrase_list, words=words)
                    last_partial = ""
                    continue

                # partial: –∏–º–∏—Ç–∞—Ü–∏—è ASR partial –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                if data.get("type") == "partial":
                    partial_text = data.get("partial", "").strip()
                    if partial_text:
                        # –ò–º–∏—Ç–∏—Ä—É–µ–º ASR partial —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                        last_partial = partial_text
                        last_partial_change_ms = now_ms()

                        part_json = {
                            "partial": partial_text,
                            "result": []
                        }
                        await safe_send_locked({"type": "partial", **part_json})
                        print(f"[ASR] –ò–º–∏—Ç–∏—Ä–æ–≤–∞–Ω ASR partial: '{partial_text}'")
                    continue

                # final: –∏–º–∏—Ç–∞—Ü–∏—è ASR final –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è - –í–´–ó–´–í–ê–ï–ú FINAL ENDPOINT –õ–û–ì–ò–ö–£
                if data.get("type") == "final":
                    final_text = data.get("text", "").strip()
                    if final_text:
                        # –ò–º–∏—Ç–∏—Ä—É–µ–º ASR final —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                        final_json = {
                            "text": final_text,
                            "result": []
                        }

                        # –í–´–ó–´–í–ê–ï–ú FINAL ENDPOINT –õ–û–ì–ò–ö–£ –ó–î–ï–°–¨
                        await handle_final_text(final_text, reason="final_json")

                        await safe_send_locked({"type": "final", **final_json})

                        # State transition: test final
                        if voice_state == VoiceState.USER_SPEAKING:
                            voice_state = VoiceState.IDLE
                        print(f"[TEST] –ò–º–∏—Ç–∏—Ä–æ–≤–∞–Ω ASR final: '{final_text}'")

                        # –ù–æ–≤–∞—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è —Ä–µ–ø–ª–∏–∫–∞ - —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è turn
                        turn_id += 1
                        ack_sent_for_turn = False
                        llm_started = False
                        current_llm_input = ""
                        pause_gate_open = True

                        # –°–±—Ä–æ—Å WPS —Å–æ—Å—Ç–æ—è–Ω–∏–π –¥–ª—è –Ω–æ–≤–æ–π —Ä–µ–ø–ª–∏–∫–∏
                        wps_ema = 2.2
                        prev_wc = 0
                        prev_wc_ts_ms = 0

                        # –°–±—Ä–æ—Å FSM endpointing —Å–æ—Å—Ç–æ—è–Ω–∏–π
                        endpoint_state = "listening"
                        endpoint_tentative_start_ms = 0
                        endpoint_confirmed_start_ms = 0

                    continue

                # ping: keep-alive –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞
                if "ping" in data:
                    # –û—Ç–≤–µ—á–∞–µ–º pong –¥–ª—è keep-alive
                    await safe_send_locked({"pong": data["ping"]})
                    continue

                # eof: —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏ –∑–∞–∫—Ä—ã—Ç—å
                if data.get("eof") == 1:
                    final_json = json.loads(rec.FinalResult())
                    final_text = (final_json.get("text") or "").strip()
                    if final_text:  # –ù–ï –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—É—Å—Ç—ã–µ final
                        await safe_send_locked({"type": "final", **final_json})
                    # –ù–æ–≤–∞—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è —Ä–µ–ø–ª–∏–∫–∞ - —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è turn
                    turn_id += 1
                    ack_sent_for_turn = False
                    llm_started = False
                    current_llm_input = ""
                    pause_gate_open = True

                    # –°–±—Ä–æ—Å WPS —Å–æ—Å—Ç–æ—è–Ω–∏–π –¥–ª—è –Ω–æ–≤–æ–π —Ä–µ–ø–ª–∏–∫–∏
                    wps_ema = 2.2
                    prev_wc = 0
                    prev_wc_ts_ms = 0
                    await ws.close(code=1000, reason="eof")
                    return

                # chat: –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≤–æ–ø—Ä–æ—Å –≤ DeepSeek API —Å streaming
                if "chat" in data:
                    question = data["chat"].strip()
                    print(f"[CHAT] –ü–æ–ª—É—á–µ–Ω –≤–æ–ø—Ä–æ—Å: '{question}'")
                    if question:
                        # –û—Ç–º–µ–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π LLM –∑–∞–ø—Ä–æ—Å –µ—Å–ª–∏ –æ–Ω –µ—â–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è
                        if current_llm_task and not current_llm_task.done():
                            print(f"[CHAT] –û—Ç–º–µ–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π LLM task")
                            current_llm_task.cancel()
                            await safe_send_locked({"type": "abort", "scope": "llm", "reason": "new_chat"})

                        async def run_llm(q: str):
                            """–ó–∞–ø—É—Å–∫ LLM streaming –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ utterance_id (chat –≤–µ—Ä—Å–∏—è)"""
                            nonlocal llm_first_token_at_ms

                            utterance_id = 1  # –î–ª—è chat –∑–∞–ø—Ä–æ—Å–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π utterance_id
                            await safe_send_locked({"type": "nlu_start", "utterance_id": utterance_id, "text": q})
                            await safe_send_locked({"type": "chat_start", "question": q})

                            first = True
                            acc = []  # –°–æ–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç
                            try:
                                async for tok in openai_stream(q, model=llm_model, system_prompt=system_prompt, max_tokens=llm_max_tokens, temperature=llm_temp):
                                    if first:
                                        llm_first_token_at_ms = now_ms()
                                        first = False
                                        await safe_send_locked({
                                            "type": "metric",
                                            "utterance_id": utterance_id,
                                            "llm_first_token_ms": llm_first_token_at_ms - llm_started_at_ms
                                        })

                                    await safe_send_locked({"type": "llm_delta", "utterance_id": utterance_id, "delta": tok})

                                    # –ö–ª–∞–¥—ë–º —Ç–æ–∫–µ–Ω –≤ –æ—á–µ—Ä–µ–¥—å –¥–ª—è TTS
                                    try:
                                        await llm_to_tts_q.put((utterance_id, tok))
                                    except asyncio.QueueFull:
                                        print(f"[LLM] –û—á–µ—Ä–µ–¥—å TTS –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–æ–∫–µ–Ω")

                            except asyncio.CancelledError:
                                # –ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –æ—Ç–º–µ–Ω–∞
                                raise
                            except Exception as e:
                                await safe_send_locked({"type": "llm_error", "utterance_id": utterance_id, "error": str(e)})
                            finally:
                                # –°–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –¥–ª—è TTS
                                try:
                                    await llm_to_tts_q.put((utterance_id, ""))
                                except asyncio.QueueFull:
                                    print(f"[LLM] –û—á–µ—Ä–µ–¥—å TTS –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞, –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è")

                                await safe_send_locked({"type": "chat_response", "question": q, "answer": "".join(acc)})
                                await safe_send_locked({"type": "llm_end", "utterance_id": utterance_id})

                        print(f"[CHAT] –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–æ–≤—ã–π LLM task –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞: '{question}'")
                        current_llm_task = asyncio.create_task(run_llm(question))
                    else:
                        print(f"[CHAT] –ü—É—Å—Ç–æ–π –≤–æ–ø—Ä–æ—Å, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    continue

                continue

            # === –û–ë–†–ê–ë–û–¢–ö–ê –ë–ò–ù–ê–†–ù–´–• –°–û–û–ë–©–ï–ù–ò–ô (PCM) ===
            else:  # –ë–∏–Ω–∞—Ä–Ω—ã–π –∞—É–¥–∏–æ-—á–∞–Ω–∫: 16-bit mono PCM little-endian
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞
                if not handshake_done:
                    proto_violation("PCM received before READY")
                    continue

                if voice_state == VoiceState.ASSISTANT_TTS:
                    proto_violation("User PCM received during ASSISTANT_TTS state - dropped")
                    continue

                pcm_data = msg
                print(f"[PCM] –ü–æ–ª—É—á–µ–Ω—ã –±–∏–Ω–∞—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {len(pcm_data)} bytes")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ PCM –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ (int16 mono)
                if len(pcm_data) % 2 != 0:
                    proto_violation(f"PCM data size {len(pcm_data)} not divisible by 2 (expected int16)")
                    continue

                expected_samples_per_20ms = int(sample_rate * 0.02)  # 20ms —Ñ—Ä–µ–π–º
                expected_bytes_per_20ms = expected_samples_per_20ms * 2  # int16 = 2 bytes
                if len(pcm_data) != expected_bytes_per_20ms:
                    proto_violation(f"Bad PCM frame size: {len(pcm_data)} bytes, expected {expected_bytes_per_20ms} bytes (20ms @ {sample_rate}Hz int16 mono)")
                    continue

                # –ü–†–û–í–ï–†–ö–ê ASR MUTE
                if not asr_enabled:
                    continue

                # ASR WARMUP: —Å–æ–±–∏—Ä–∞–µ–º –±—É—Ñ–µ—Ä –≤ —Ç–µ—á–µ–Ω–∏–∏ ASR_WARMUP_MS
                if asr_warming_up:
                    # –î–æ–±–∞–≤–ª—è–µ–º PCM –≤ –±—É—Ñ–µ—Ä
                    audio_buf.extend(pcm_data)

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ warmup
                    if time.time() >= asr_warmup_deadline:
                        asr_warming_up = False
                        # –ú—è–≥–∫–∏–π —Å–±—Ä–æ—Å VAD (—Ç–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å—á–µ—Ç—á–∏–∫–∏)
                        vad.soft_reset()
                        print("[ASR] Warmup completed, ASR fully active, processing buffered audio")
                        # –ù–ï continue - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π –±—É—Ñ–µ—Ä —Å—Ä–∞–∑—É
                    else:
                        continue  # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å–æ–±–∏—Ä–∞—Ç—å –±—É—Ñ–µ—Ä
                else:
                    # –ù–æ—Ä–º–∞–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞: –¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π PCM –≤ –±—É—Ñ–µ—Ä
                    print(f"[AUDIO] –ü–æ–ª—É—á–µ–Ω —á–∞–Ω–∫: {len(pcm_data)} bytes, –±—É—Ñ–µ—Ä: {len(audio_buf)}")
                    audio_buf.extend(pcm_data)

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ –ø–æ —Ñ—Ä–µ–π–º–∞–º
                frames_processed = 0
                while len(audio_buf) >= fb:
                    frame = bytes(audio_buf[:fb])
                    del audio_buf[:fb]
                    frames_processed += 1

                    # 1) VAD: –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ—á—å/—Ç–∏—à–∏–Ω—É
                    try:
                        is_voice = vad.is_speech(frame, sample_rate)
                    except ValueError as e:
                        # –ó–∞—â–∏—Ç–∞ –æ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ñ—Ä–µ–π–º–∞ / –Ω–µ—Å–æ—Å—Ç—ã–∫–æ–≤–∫–∏ sample_rate
                        print(f"[VAD] Frame mismatch error: {e} (frame_len={len(frame)}, sample_rate={sample_rate})")
                        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –±—É—Ñ–µ—Ä –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É (–Ω–µ —Ä–≤—ë–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ)
                        audio_buf.clear()
                        continue
                    if is_voice:
                        last_voice_ms = now_ms()
                        print(f"[VAD] –†–µ—á—å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –≤ —Ñ—Ä–µ–π–º–µ {frames_processed}")
                        
                        # –ï—Å–ª–∏ –º—ã –±—ã–ª–∏ –≤ IDLE, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ USER_SPEAKING
                        if voice_state == VoiceState.IDLE:
                            voice_state = VoiceState.USER_SPEAKING
                            print("[STATE] IDLE ‚Üí USER_SPEAKING")
                    else:
                        print(f"[VAD] –¢–∏—à–∏–Ω–∞ –≤ —Ñ—Ä–µ–π–º–µ {frames_processed}")

                    # ---------- –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–∞—É–∑ –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç–∏ ----------
                    if was_voice_prev and (not is_voice):
                        silence_start_ms = now_ms()
                    if (not was_voice_prev) and is_voice and silence_start_ms:
                        pause_ms = now_ms() - silence_start_ms
                        pause_ema_ms = update_pause_ema(pause_ema_ms, pause_ms, PAUSE_EMA_ALPHA)
                        silence_start_ms = 0
                    was_voice_prev = is_voice

                    # ---------- BARGE-IN ARMING (—Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —Ç–∏—à–∏–Ω—ã) ----------
                    if output_active:
                        if not is_voice:
                            silent_run_ms += FRAME_MS
                            if silent_run_ms >= BARGE_IN_ARM_SILENCE_MS:
                                barge_armed = True
                        else:
                            silent_run_ms = 0
                    else:
                        # –µ—Å–ª–∏ –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ ‚Äî —Å–±—Ä–∞—Å—ã–≤–∞–µ–º
                        barge_armed = False
                        silent_run_ms = 0
                        voice_run_ms = 0

                    # ---------- BARGE-IN (–ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞) ----------
                    if BARGE_IN_ENABLED and output_active and is_voice:
                        now_bi = now_ms()

                        # 1) –ø–æ–∫–∞ –æ–∑–≤—É—á–∫–∞ "–∏–¥—ë—Ç" ‚Äî barge-in –∑–∞–ø—Ä–µ—â—ë–Ω (–∏–Ω–∞—á–µ —ç—Ö–æ —Ä—É–±–∏—Ç)
                        if tts_playing:
                            voice_run_ms = 0

                        # 2) –µ—â—ë –Ω–µ –±—ã–ª–æ —Ç–∏—à–∏–Ω—ã –≤–æ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ ‚Üí —ç—Ç–æ —Ö–≤–æ—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π —Ä–µ–ø–ª–∏–∫–∏, –ù–ï barge-in
                        elif not barge_armed:
                            voice_run_ms = 0

                        # 3) cooldown
                        elif now_bi - last_barge_in_ms < BARGE_IN_COOLDOWN_MS:
                            pass

                        # 4) –∞–Ω—Ç–∏-—ç—Ö–æ –æ–∫–Ω–æ –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ
                        elif now_bi - last_tts_chunk_ms < BARGE_IN_IGNORE_AFTER_TTS_MS:
                            voice_run_ms = 0

                        else:
                            voice_run_ms += FRAME_MS
                            if voice_run_ms >= BARGE_IN_MIN_VOICE_MS:
                                await abort_output("barge_in_user_speaking")
                    else:
                        if not is_voice:
                            voice_run_ms = 0

                    # 2) ASR: —Å–∫–∞—Ä–º–ª–∏–≤–∞–µ–º Vosk —Ç–æ—Ç –∂–µ —Ñ—Ä–µ–π–º
                    # –ï—Å–ª–∏ –∏–¥—ë—Ç –æ–∑–≤—É—á–∫–∞ ‚Äî –Ω–µ –ø—É—Å–∫–∞–µ–º –∞—É–¥–∏–æ –≤ ASR, –∏–Ω–∞—á–µ –ª–æ–≤–∏–º —ç—Ö–æ TTS
                    if output_active and tts_playing:
                        continue
                    # –î–æ–ø. –æ–∫–Ω–æ –ø–æ—Å–ª–µ —á–∞–Ω–∫–∞ TTS
                    if output_active and (now_ms() - last_tts_chunk_ms) < BARGE_IN_IGNORE_AFTER_TTS_MS:
                        continue
                    ok = await decode_accept(rec, frame)

                    if ok:
                        # Vosk —Ä–µ—à–∏–ª, —á—Ç–æ —Ñ—Ä–∞–∑–∞ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å (–ø–æ —Å–≤–æ–µ–π –ª–æ–≥–∏–∫–µ)
                        final_json = json.loads(rec.Result())
                        final_text = (final_json.get("text") or "").strip()
                        if final_text:  # –ù–ï –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—É—Å—Ç—ã–µ final
                            await safe_send_locked({"type": "final", **final_json})

                            # State transition: user finished speaking, starting LLM
                            voice_state = VoiceState.IDLE
                            print("[STATE] USER_SPEAKING ‚Üí IDLE (final received)")

                        # –í–ê–ñ–ù–û: –ó–∞–ø—É—Å–∫ LLM –ø–æ final –∏–∑ Vosk (rec.Result())
                        await handle_final_text(final_json.get("text"), reason="final_vosk_result")

                        # —Å–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏–π –ø–æ–¥ –Ω–æ–≤—É—é —Ñ—Ä–∞–∑—É
                        last_partial = ""
                        last_partial_change_ms = now_ms()
                        early_endpoint_fired = False
                        # –°–ë–†–û–°: –Ω–æ–≤–∞—è —Ñ—Ä–∞–∑–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                        llm_started = False
                        current_llm_input = ""
                        continue

                    # 3) partial: –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É + –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
                    now = now_ms()
                    if now - last_partial_sent_ms >= PARTIAL_RATE_LIMIT_MS:
                        part_json = json.loads(rec.PartialResult())
                        partial = (part_json.get("partial") or "").strip()

                        if partial and partial != last_partial:
                            # –ï—Å–ª–∏ –º—ã –ø–æ–ª—É—á–∏–ª–∏ —Ç–µ–∫—Å—Ç, –∞ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤—Å—ë –µ—â–µ IDLE - –∑–Ω–∞—á–∏—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞—á–∞–ª –≥–æ–≤–æ—Ä–∏—Ç—å
                            if voice_state == VoiceState.IDLE:
                                voice_state = VoiceState.USER_SPEAKING
                                print(f"[STATE] IDLE ‚Üí USER_SPEAKING (detected by partial: '{partial[:30]}')")

                            # –§–∏–ª—å—Ç—Ä tail jitter: –Ω–µ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –Ω–∞ –º–µ–ª–∫–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ö–≤–æ—Å—Ç–∞
                            if not is_tail_jitter(partial, last_partial):
                                last_partial_change_ms = now

                                # –û–±–Ω–æ–≤–ª—è–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å —Ä–µ—á–∏
                                curr_wc = word_count(partial)
                                if prev_wc_ts_ms > 0 and curr_wc > prev_wc:
                                    dt = now - prev_wc_ts_ms
                                    wps_ema = update_wps_ema(wps_ema, prev_wc, curr_wc, dt)
                                prev_wc = curr_wc
                                prev_wc_ts_ms = now

                            last_partial = partial
                            await safe_send_locked({"type": "partial", **part_json})
                            last_partial_sent_ms = now


                    # 4) FSM Endpointing –ª–æ–≥–∏–∫–∞: listening -> tentative -> confirmed -> final
                    silent_ms = now - last_voice_ms
                    stable_ms = now - last_partial_change_ms

                    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Ç–µ–∫—Å—Ç–∞
                    if last_partial:
                        tent_ms, conf_ms, fin_ms = compute_adaptive_thresholds(last_partial, wps_ema, pause_ema_ms)
                    else:
                        tent_ms, conf_ms, fin_ms = 350, 1100, 1600  # –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è

                    # FSM –ª–æ–≥–∏–∫–∞ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤
                    print(f"[ENDPOINT] state={endpoint_state} | silence={silent_ms}ms | stable={stable_ms}ms | text='{last_partial[:50]}...'")

                    if endpoint_state == "listening":
                        # –ü–µ—Ä–µ—Ö–æ–¥ –≤ tentative –ø—Ä–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π –ø–∞—É–∑–µ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                        if (last_partial and is_meaningful(last_partial) and
                            stable_ms >= 300 and silent_ms >= tent_ms):
                            endpoint_state = "tentative"
                            endpoint_tentative_start_ms = now
                            print(f"[ENDPOINT] ‚Üí tentative (tent_ms={tent_ms})")

                            await safe_send_locked({
                                "type": "asr_tentative_pause",
                                "text": last_partial,
                                "silent_ms": silent_ms,
                                "stable_ms": stable_ms,
                                "tentative_ms": tent_ms,
                                "confirm_ms": conf_ms
                            })

                            # LLM —Å—Ç–∞—Ä—Ç—É–µ—Ç –¢–û–õ–¨–ö–û –∏–∑ final - —É–±–∏—Ä–∞–µ–º tentative_pause

                    elif endpoint_state == "tentative":
                        # –í–æ–∑–≤—Ä–∞—Ç –≤ listening –µ—Å–ª–∏ partial –∏–∑–º–µ–Ω–∏–ª—Å—è
                        if last_partial and last_partial != part_json.get("partial", ""):
                            endpoint_state = "listening"
                            print("[ENDPOINT] ‚Üê listening (partial changed)")
                        # –ü–µ—Ä–µ—Ö–æ–¥ –≤ confirmed –ø—Ä–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π –ø–∞—É–∑–µ –∏ —Ö–æ—Ä–æ—à–µ–º –∫–æ–Ω—Ü–µ
                        elif (silent_ms >= conf_ms and stable_ms >= 500 and
                              last_partial and is_good_end(last_partial)):
                            endpoint_state = "confirmed"
                            endpoint_confirmed_start_ms = now
                            print(f"[ENDPOINT] ‚Üí confirmed (conf_ms={conf_ms})")

                            await safe_send_locked({
                                "type": "asr_confirmed_end",
                                "text": last_partial,
                                "silent_ms": silent_ms,
                                "stable_ms": stable_ms,
                                "confirm_ms": conf_ms,
                                "tentative_ms": tent_ms,
                                "final_ms": fin_ms,
                                "pause_ema_ms": pause_ema_ms,
                                "wps_ema": wps_ema,
                                "word_count": len(last_partial.strip().split()),
                                "is_good_end": is_good_end(last_partial)
                            })

                            # LLM —Å—Ç–∞—Ä—Ç—É–µ—Ç –¢–û–õ–¨–ö–û –∏–∑ final - confirmed_end_start —É–¥–∞–ª–µ–Ω

                    elif endpoint_state == "confirmed":
                        # –í–æ–∑–≤—Ä–∞—Ç –≤ listening –µ—Å–ª–∏ partial –∏–∑–º–µ–Ω–∏–ª—Å—è
                        if last_partial and last_partial != part_json.get("partial", ""):
                            endpoint_state = "listening"
                            print("[ENDPOINT] ‚Üê listening (partial changed in confirmed)")
                        # –ü–µ—Ä–µ—Ö–æ–¥ –≤ final –ø—Ä–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø–∞—É–∑–µ
                        elif silent_ms >= fin_ms:
                            endpoint_state = "final"
                            print(f"[ENDPOINT] ‚Üí final (fin_ms={fin_ms})")

                    # –°–±—Ä–æ—Å FSM –ø—Ä–∏ –Ω–∞—á–∞–ª–µ –Ω–æ–≤–æ–π —Ä–µ—á–∏
                    if is_voice and endpoint_state != "listening":
                        endpoint_state = "listening"
                        print("[ENDPOINT] ‚Üê listening (voice detected)")

                    # FINAL ENDPOINT: –¥–ª–∏–Ω–Ω–∞—è –ø–∞—É–∑–∞ -> —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–æ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–º (–Ω–µ –ø–æ JSON)
                    if last_partial and silent_ms >= fin_ms:
                        final_json = json.loads(rec.FinalResult())
                        final_text = (final_json.get("text") or "").strip()
                        if final_text:  # –ù–ï –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—É—Å—Ç—ã–µ final
                            await safe_send_locked({"type": "final", **final_json})

                            # State transition: user finished speaking (pause timeout)
                            if voice_state == VoiceState.USER_SPEAKING:
                                voice_state = VoiceState.IDLE

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å/–ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å LLM –ø–æ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º—É —Ç–µ–∫—Å—Ç—É
                        await handle_final_text(final_json.get("text"), reason="final_pause")

                        # –ù–æ–≤–∞—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è —Ä–µ–ø–ª–∏–∫–∞ - —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è turn
                        turn_id += 1
                        ack_sent_for_turn = False
                        llm_started = False  # –°–ë–†–û–°: —Ä–∞–∑—Ä–µ—à–∞–µ–º –∑–∞–ø—É—Å–∫ LLM –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π —Ä–µ–ø–ª–∏–∫–∏
                        current_llm_input = ""  # –°–ë–†–û–°: –æ—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π input
                        pause_gate_open = True

                        # –°–±—Ä–æ—Å WPS —Å–æ—Å—Ç–æ—è–Ω–∏–π –¥–ª—è –Ω–æ–≤–æ–π —Ä–µ–ø–ª–∏–∫–∏
                        wps_ema = 2.2
                        prev_wc = 0
                        prev_wc_ts_ms = 0

                        # –°–±—Ä–æ—Å FSM endpointing —Å–æ—Å—Ç–æ—è–Ω–∏–π
                        endpoint_state = "listening"
                        endpoint_tentative_start_ms = 0
                        endpoint_confirmed_start_ms = 0

                        # –ø–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º recognizer –ø–æ–¥ —Å–ª–µ–¥—É—é—â—É—é —Ñ—Ä–∞–∑—É
                        rec = build_recognizer(sample_rate, phrase_list=phrase_list, words=words)

                        last_partial = ""
                        last_partial_change_ms = now_ms()
                        early_endpoint_fired = False

    except websockets.exceptions.ConnectionClosed as e:
        logger.info(f"WebSocket connection closed normally: {e.code} {e.reason}")
        # Cancel –∞–∫—Ç–∏–≤–Ω—ã–µ tasks –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        if current_chat_task and not current_chat_task.done():
            current_chat_task.cancel()
        if current_llm_task and not current_llm_task.done():
            current_llm_task.cancel()
        if tts_task and not tts_task.done():
            tts_task.cancel()
        return
    except Exception as e:
        print(f"[HANDLER][FATAL] Unexpected error: {e}")
        import traceback
        traceback.print_exc()
        logger.exception("handler crashed with unexpected error")
        # –ö–æ—Ä–æ—Ç–∫–∞—è –ø—Ä–∏—á–∏–Ω–∞ (reason –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–º)
        try:
            await ws.close(code=1011, reason="internal_error")
        except:
            pass
    finally:
        # –û—Ç–º–µ–Ω—è–µ–º –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        print("[HANDLER] –ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è, –æ—Ç–º–µ–Ω—è–µ–º –∑–∞–¥–∞—á–∏")
        if tts_task and not tts_task.done():
            tts_task.cancel()
            print("[HANDLER] TTS task –æ—Ç–º–µ–Ω–µ–Ω")


async def main():
    print(f"[boot] ws://{HOST}:{PORT}, health:{HEALTH_PORT}")

    # Graceful shutdown event
    stop_event = asyncio.Event()

    def _stop(*_):
        print("[SHUTDOWN] –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è")
        stop_event.set()

    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤
    loop = asyncio.get_running_loop()
    for s in (signal.SIGTERM, signal.SIGINT):
        loop.add_signal_handler(s, _stop)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º HTTP –∫–ª–∏–µ–Ω—Ç—ã
    await init_openai_http()
    if TTS_PROVIDER == "openai":
        await init_tts_api_http()
    await init_tts_http()

    # –ó–∞–ø—É—Å–∫–∞–µ–º health —Å–µ—Ä–≤–µ—Ä
    health_srv = await health_server()

    async def cleanup_sessions_task():
        while True:
            await asyncio.sleep(60)
            now = now_ms()
            ttl = 10 * 60 * 1000  # 10 –º–∏–Ω—É—Ç
            dead = []
            for sid, sess in SESSIONS.items():
                if sess.ended and sess.ended_at_ms and (now - sess.ended_at_ms) > ttl:
                    dead.append(sid)
            for sid in dead:
                SESSIONS.pop(sid, None)
                print(f"[SESSION] cleaned {sid}")

    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º cleanup task
        asyncio.create_task(cleanup_sessions_task())

        # –û—Ç–∫–ª—é—á–∞–µ–º compression –¥–ª—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ CPU overhead –∏ latency
        async with websockets.serve(
            handler,
            HOST,
            PORT,
            compression=None,  # –û–¢–ö–õ–Æ–ß–ê–ï–ú COMPRESSION –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            max_size=4 * 1024 * 1024,  # –£–º–µ–Ω—å—à–∞–µ–º –ª–∏–º–∏—Ç –¥–ª—è –∑–∞—â–∏—Ç—ã
            ping_interval=None,  # –û—Ç–∫–ª—é—á–∞–µ–º ping - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª–∏–µ–Ω—Ç—Å–∫–∏–π keep-alive
            ping_timeout=None,
        ):
            print("[boot] WS —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω, –∂–¥–µ–º —Å–∏–≥–Ω–∞–ª–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è...")
            await stop_event.wait()
            print("[SHUTDOWN] –ù–∞—á–∏–Ω–∞–µ–º graceful shutdown...")
    finally:
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º HTTP –∫–ª–∏–µ–Ω—Ç—ã
        await close_openai_http()
        await close_tts_api_http()
        await close_tts_http()

        # –ó–∞–∫—Ä—ã–≤–∞–µ–º health —Å–µ—Ä–≤–µ—Ä
        if health_srv:
            health_srv.close()
            await health_srv.wait_closed()
            print("[SHUTDOWN] Health —Å–µ—Ä–≤–µ—Ä –∑–∞–∫—Ä—ã—Ç")

        print("[SHUTDOWN] Graceful shutdown –∑–∞–≤–µ—Ä—à–µ–Ω")


if __name__ == "__main__":
    asyncio.run(main())

