import { useState, useRef, useEffect, useCallback, useMemo } from "react";

/** types –æ—Å—Ç–∞–≤–ª—è—é –≤–∞—à–∏ –∫–∞–∫ –µ—Å—Ç—å */
interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
  resultIndex: number;
}
interface SpeechRecognitionErrorEvent extends Event {
  error: string;
  message?: string;
}
interface SpeechRecognitionResultList {
  readonly length: number;
  item(index: number): SpeechRecognitionResult;
  [index: number]: SpeechRecognitionResult;
}
interface SpeechRecognitionResult {
  readonly length: number;
  item(index: number): SpeechRecognitionAlternative;
  [index: number]: SpeechRecognitionAlternative;
  isFinal: boolean;
}
interface SpeechRecognitionAlternative {
  transcript: string;
  confidence: number;
}
interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  grammars: SpeechGrammarList;
  interimResults: boolean;
  lang: string;
  maxAlternatives: number;
  serviceURI: string;
  start(): void;
  stop(): void;
  abort(): void;
  onaudiostart: ((this: SpeechRecognition, ev: Event) => void) | null;
  onaudioend: ((this: SpeechRecognition, ev: Event) => void) | null;
  onend: ((this: SpeechRecognition, ev: Event) => void) | null;
  onerror: ((this: SpeechRecognition, ev: SpeechRecognitionErrorEvent) => void) | null;
  onnomatch: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => void) | null;
  onresult: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => void) | null;
  onsoundstart: ((this: SpeechRecognition, ev: Event) => void) | null;
  onsoundend: ((this: SpeechRecognition, ev: Event) => void) | null;
  onspeechstart: ((this: SpeechRecognition, ev: Event) => void) | null;
  onspeechend: ((this: SpeechRecognition, ev: Event) => void) | null;
  onstart: ((this: SpeechRecognition, ev: Event) => void) | null;
}
interface SpeechGrammarList {
  readonly length: number;
  item(index: number): SpeechGrammar;
  [index: number]: SpeechGrammar;
  addFromURI(src: string, weight?: number): void;
  addFromString(string: string, weight?: number): void;
}
interface SpeechGrammar {
  src: string;
  weight: number;
}

type VoiceErrorCode =
  | "not-allowed"
  | "no-speech"
  | "audio-capture"
  | "network"
  | "aborted"
  | "start-failed"
  | "start-timeout"
  | "not-supported"
  | string;

interface UseVoiceInputOptions {
  lang?: string;
  onTranscript?: (transcript: string) => void;
  onError?: (code: VoiceErrorCode, message?: string) => void;
}

interface UseVoiceInputReturn {
  isRecording: boolean;
  isSupported: boolean;
  isAppleDevice: boolean;
  startRecording: () => Promise<boolean>;
  stopRecording: () => void;
  toggleRecording: () => void;
}

export const useVoiceInput = ({
  lang = "ru-RU",
  onTranscript,
  onError,
}: UseVoiceInputOptions = {}): UseVoiceInputReturn => {
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const lastTranscriptRef = useRef<string>("");

  const [isSupported, setIsSupported] = useState(false);
  const [isRecording, setIsRecording] = useState(false);

  // –ì–≤–∞—Ä–¥—ã –æ—Ç –≥–æ–Ω–æ–∫/–¥—É–±–ª–µ–π (refs = —Å—Ç–∞–±–∏–ª—å–Ω—ã–π mutex)
  const isStartingRef = useRef(false);
  const stopRequestedRef = useRef(false);
  const ignoreErrorsRef = useRef(false);
  const isRecordingRef = useRef(false); // Ref –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –∑–∞–ø–∏—Å–∏

  // callbacks —á–µ—Ä–µ–∑ refs (—á—Ç–æ–±—ã –ù–ï –ø–µ—Ä–µ—Å–æ–∑–¥–∞–≤–∞—Ç—å recognition –ø—Ä–∏ –∫–∞–∂–¥–æ–º —Ä–µ–Ω–¥–µ—Ä–µ)
  const onTranscriptRef = useRef<typeof onTranscript>(onTranscript);
  const onErrorRef = useRef<typeof onError>(onError);

  // watchdog, —á—Ç–æ–±—ã isStarting –Ω–µ –º–æ–≥ –∑–∞–≤–∏—Å–Ω—É—Ç—å
  const startTimeoutRef = useRef<number | null>(null);

  const isAppleDevice = useMemo(() => {
    if (typeof navigator === "undefined") return false;
    const ua = navigator.userAgent || "";
    const isMac = /Macintosh|MacIntel|MacPPC|Mac68K/.test(ua);
    const isIOS = /iPad|iPhone|iPod/.test(ua);
    const iPadOS13Plus = navigator.platform === "MacIntel" && (navigator as any).maxTouchPoints > 1;
    return isMac || isIOS || iPadOS13Plus;
  }, []);

  useEffect(() => {
    onTranscriptRef.current = onTranscript;
    onErrorRef.current = onError;
  }, [onTranscript, onError]);

  const clearStartTimeout = () => {
    if (startTimeoutRef.current) {
      window.clearTimeout(startTimeoutRef.current);
      startTimeoutRef.current = null;
    }
  };

  const hardResetFlags = () => {
    clearStartTimeout();
    isStartingRef.current = false;
    stopRequestedRef.current = false;
    isRecordingRef.current = false;
    setIsRecording(false);
  };

  const createRecognition = useCallback(() => {
    const w = window as any;
    const Ctor = w.SpeechRecognition || w.webkitSpeechRecognition;

    if (!Ctor) {
      console.warn("üé§ Speech Recognition API not available");
      setIsSupported(false);
      return null;
    }

    const rec: SpeechRecognition = new Ctor();
    // –ù–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö Apple (iOS –∏ macOS) continuous —Ä–µ–∂–∏–º —á–∞—Å—Ç–æ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –æ—à–∏–±–∫–µ 1107, 
    // –∞ —Ç–∞–∫–∂–µ Safari —Ç—Ä–µ–±—É–µ—Ç –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ start() –±–µ–∑ await –≤ —Ü–µ–ø–æ—á–∫–µ.
    rec.continuous = !isAppleDevice; 
    // –û—Ç–∫–ª—é—á–∞–µ–º interimResults –¥–ª—è Apple –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    rec.interimResults = !isAppleDevice;
    rec.lang = lang;

    rec.onstart = () => {
      console.log("üé§ Speech recognition started successfully");
      lastTranscriptRef.current = ""; // –°–±—Ä–æ—Å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
      clearStartTimeout();
      isStartingRef.current = false;
      stopRequestedRef.current = false;
      isRecordingRef.current = true;
      setIsRecording(true);
    };

    rec.onend = () => {
      console.log("üé§ Speech recognition ended", { lastTranscript: lastTranscriptRef.current });
      // –ï—Å–ª–∏ –æ—Å—Ç–∞–ª—Å—è –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–∏ —Ä—É—á–Ω–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–µ)
      if (lastTranscriptRef.current.trim() && stopRequestedRef.current) {
        console.log("üé§ Sending remaining transcript on manual stop:", lastTranscriptRef.current.trim());
        onTranscriptRef.current?.(lastTranscriptRef.current.trim());
      }
      hardResetFlags();
    };

    rec.onresult = (event: SpeechRecognitionEvent) => {
      let interimTranscript = "";
      let finalTranscript = "";

      for (let i = event.resultIndex; i < event.results.length; ++i) {
        const transcript = event.results[i][0].transcript;
        if (event.results[i].isFinal) {
          finalTranscript += transcript;
        } else {
          interimTranscript += transcript;
        }
      }

      const currentText = (finalTranscript || interimTranscript).trim();
      if (currentText) {
        lastTranscriptRef.current = currentText;
        console.log("üé§ Speech recognition update:", { final: finalTranscript, interim: interimTranscript });
      }

      // –ù–ï –≤—ã–∑—ã–≤–∞–µ–º onTranscript –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ
      // –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –µ–≥–æ –≤ lastTranscriptRef –∏ –≤—ã–∑–æ–≤–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —è–≤–Ω–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–µ
      if (finalTranscript.trim()) {
        console.log("üé§ Speech recognition result (final) - saved, will send on manual stop:", finalTranscript.trim());
        // –ù–ï –≤—ã–∑—ã–≤–∞–µ–º onTranscript –∑–¥–µ—Å—å - —Ç–æ–ª—å–∫–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
        // onTranscript –±—É–¥–µ—Ç –≤—ã–∑–≤–∞–Ω –≤ rec.onend –ø—Ä–∏ stopRequestedRef.current === true
      }
    };

    rec.onerror = (event: SpeechRecognitionErrorEvent) => {
      const code = (event as any)?.error as VoiceErrorCode;
      const msg = (event as any)?.message as string | undefined;
      console.error("üé§ Speech recognition error:", { code, msg, event });

      if (ignoreErrorsRef.current) return;

      // aborted –ø—Ä–∏ stop/blur –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö Apple ‚Äî –Ω–µ —ç—Å–∫–∞–ª–∏—Ä—É–µ–º, –µ—Å–ª–∏ –º—ã —Å–∞–º–∏ –ø—Ä–æ—Å–∏–ª–∏ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å
      if (code === "aborted") {
        if (stopRequestedRef.current) {
          hardResetFlags();
          return;
        }
        // –ï—Å–ª–∏ —ç—Ç–æ –æ—à–∏–±–∫–∞ 1107 –∏–ª–∏ —Å–∏—Å—Ç–µ–º–Ω—ã–π —Å–±—Ä–æ—Å –±–µ–∑ –Ω–∞—à–µ–π –ø—Ä–æ—Å—å–±—ã
        console.warn("üé§ System aborted recognition (Apple device issue 1107 possible)");
      }

      hardResetFlags();
      onErrorRef.current?.(code, msg || (code === "aborted" ? "–°–±–æ–π –¥–∏–∫—Ç–æ–≤–∫–∏ Apple. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –Ω–∞–∂–∞—Ç—å –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Siri." : undefined));
    };

    return rec;
  }, [lang, isAppleDevice]);

  // –°–æ–∑–¥–∞—ë–º recognition —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —Å–º–µ–Ω–µ lang (–∞ –Ω–µ –ø—Ä–∏ –∫–∞–∂–¥–æ–º —Ä–µ–Ω–¥–µ—Ä–µ)
  useEffect(() => {
    ignoreErrorsRef.current = false;

    // –≤–∞–∂–Ω—ã–π reset –Ω–∞ –º–∞—É–Ω—Ç–µ —ç—Ñ—Ñ–µ–∫—Ç–∞ (–∑–∞–∫—Ä—ã–≤–∞–µ—Ç "–∑–∞–ª–∏–ø–∞–Ω–∏—è" –ø–æ—Å–ª–µ HMR/cleanup)
    hardResetFlags();

    const rec = createRecognition();
    if (!rec) return;

    recognitionRef.current = rec;
    setIsSupported(true);

    return () => {
      ignoreErrorsRef.current = true;

      // –∂—ë—Å—Ç–∫–æ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥–∏ –∑–¥–µ—Å—å, –ø–æ—Ç–æ–º—É —á—Ç–æ onend/onerror –º–æ–≥—É—Ç –Ω–µ —Å—Ä–∞–±–æ—Ç–∞—Ç—å
      hardResetFlags();

      try {
        rec.onstart = null as any;
        rec.onend = null as any;
        rec.onresult = null as any;
        rec.onerror = null as any;
        rec.onaudiostart = null as any;

        // abort –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ; stop —á–∞—Å—Ç–æ –¥–∞—ë—Ç –ª–∏—à–Ω–∏–µ aborted
        rec.abort();
      } catch {
        /* no-op */
      } finally {
        recognitionRef.current = null;
      }
    };
  }, [createRecognition]);

  const startRecording = useCallback(async (): Promise<boolean> => {
    const rec = recognitionRef.current;
    console.log("üé§ startRecording called, rec exists:", !!rec, "isStarting:", isStartingRef.current, "isRecording:", isRecording);

    if (!rec) {
      console.error("üé§ No recognition instance available");
      onErrorRef.current?.("not-supported", "SpeechRecognition instance –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç");
      return false;
    }

    if (isStartingRef.current || isRecording) {
      console.log("üé§ Recording already in progress or starting");
      return false;
    }

    if (isAppleDevice) {
      // –î–ª—è Apple/Safari —Å–æ–∑–¥–∞–µ–º –ù–û–í–´–ô —ç–∫–∑–µ–º–ø–ª—è—Ä –ø—Ä—è–º–æ –∑–¥–µ—Å—å –∏ —Å–µ–π—á–∞—Å,
      // —Ç–∞–∫ –∫–∞–∫ Safari –º–æ–∂–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ "—Å—Ç–∞—Ä—ã—Ö" –æ–±—ä–µ–∫—Ç–æ–≤ –¥–∏–∫—Ç–æ–≤–∫–∏
      // –∏–ª–∏ —Ç—Ä–µ–±–æ–≤–∞—Ç—å —Å–æ–∑–¥–∞–Ω–∏—è –≤ —Ç–æ–º –∂–µ —Å—Ç–µ–∫–µ –≤—ã–∑–æ–≤–∞, —á—Ç–æ –∏ –∫–ª–∏–∫.
      try {
        const w = window as any;
        const Ctor = w.SpeechRecognition || w.webkitSpeechRecognition;
        if (!Ctor) throw new Error("SpeechRecognition not supported");

        const appleRec = new Ctor();
        appleRec.continuous = false; // –°—Ç—Ä–æ–≥–æ false –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ Apple
        appleRec.interimResults = false; // –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        appleRec.lang = lang;

        appleRec.onstart = () => {
          console.log("üé§ Apple/Safari: Recognition started");
          isStartingRef.current = false;
          isRecordingRef.current = true;
          setIsRecording(true);
          clearStartTimeout();
        };

        appleRec.onerror = (event: any) => {
          const code = event.error;
          console.error("üé§ Apple/Safari: Recognition error:", code, event);
          hardResetFlags();
          if (code !== 'aborted') {
            onErrorRef.current?.(code, "–°–±–æ–π –¥–∏–∫—Ç–æ–≤–∫–∏ Apple. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.");
          }
        };

        appleRec.onend = () => {
          console.log("üé§ Apple/Safari: Recognition ended", { stopRequested: stopRequestedRef.current, isRecording: isRecordingRef.current });
          // –ï—Å–ª–∏ –±—ã–ª–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Ä—É—á–Ω—É—é, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –∏ –∑–∞–≤–µ—Ä—à–∞–µ–º
          if (stopRequestedRef.current) {
            if (lastTranscriptRef.current.trim()) {
              console.log("üé§ Apple/Safari: Sending accumulated transcript on manual stop (main):", lastTranscriptRef.current.trim());
              onTranscriptRef.current?.(lastTranscriptRef.current.trim());
            }
            hardResetFlags();
            return;
          }
          // –ï—Å–ª–∏ –∑–∞–ø–∏—Å—å –Ω–µ –±—ã–ª–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –≤—Ä—É—á–Ω—É—é, –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –∑–∞–ø–∏—Å–∏
          if (isRecordingRef.current) {
            console.log("üé§ Apple/Safari: Auto-restarting recognition to continue recording");
            // –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–æ–º –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            setTimeout(() => {
              if (!stopRequestedRef.current && isRecordingRef.current) {
                try {
                  const newAppleRec = new (window as any).webkitSpeechRecognition();
                  newAppleRec.continuous = false;
                  newAppleRec.interimResults = false;
                  newAppleRec.lang = lang;
                  
                  newAppleRec.onstart = () => {
                    console.log("üé§ Apple/Safari: Recognition restarted");
                    isRecordingRef.current = true;
                    setIsRecording(true);
                    recognitionRef.current = newAppleRec;
                  };
                  
                  newAppleRec.onerror = (event: any) => {
                    const code = event.error;
                    console.error("üé§ Apple/Safari: Recognition error (restart):", code, event);
                    // –ï—Å–ª–∏ —ç—Ç–æ –±—ã–ª–∞ —Ä—É—á–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ (aborted), –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
                    if (code === 'aborted' && stopRequestedRef.current && lastTranscriptRef.current.trim()) {
                      console.log("üé§ Apple/Safari: Sending accumulated transcript on manual stop (error aborted):", lastTranscriptRef.current.trim());
                      onTranscriptRef.current?.(lastTranscriptRef.current.trim());
                      hardResetFlags();
                      return;
                    }
                    if (code !== 'aborted' && !stopRequestedRef.current) {
                      hardResetFlags();
                      onErrorRef.current?.(code, "–°–±–æ–π –¥–∏–∫—Ç–æ–≤–∫–∏ Apple. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.");
                    } else if (code === 'aborted' && stopRequestedRef.current) {
                      // –ï—Å–ª–∏ —ç—Ç–æ aborted –ø—Ä–∏ —Ä—É—á–Ω–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–µ, –ø—Ä–æ—Å—Ç–æ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥–∏
                      hardResetFlags();
                    }
                  };
                  
                  newAppleRec.onend = () => {
                    console.log("üé§ Apple/Safari: Recognition ended (restart)", { stopRequested: stopRequestedRef.current, isRecording: isRecordingRef.current });
                    // –ï—Å–ª–∏ –±—ã–ª–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Ä—É—á–Ω—É—é, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
                    if (stopRequestedRef.current && lastTranscriptRef.current.trim()) {
                      console.log("üé§ Apple/Safari: Sending accumulated transcript on manual stop (restart):", lastTranscriptRef.current.trim());
                      onTranscriptRef.current?.(lastTranscriptRef.current.trim());
                      hardResetFlags();
                      return;
                    }
                    // –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ –Ω–µ –±—ã–ª–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Ä—É—á–Ω—É—é
                    if (!stopRequestedRef.current && isRecordingRef.current) {
                      setTimeout(() => {
                        if (!stopRequestedRef.current && isRecordingRef.current) {
                          newAppleRec.start();
                        } else {
                          // –ï—Å–ª–∏ —Ñ–ª–∞–≥ –∏–∑–º–µ–Ω–∏–ª—Å—è –≤–æ –≤—Ä–µ–º—è –∑–∞–¥–µ—Ä–∂–∫–∏, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
                          if (stopRequestedRef.current && lastTranscriptRef.current.trim()) {
                            console.log("üé§ Apple/Safari: Sending accumulated transcript on manual stop (delayed):", lastTranscriptRef.current.trim());
                            onTranscriptRef.current?.(lastTranscriptRef.current.trim());
                          }
                          hardResetFlags();
                        }
                      }, 100);
                    } else {
                      hardResetFlags();
                    }
                  };
                  
                  newAppleRec.onresult = (event: any) => {
                    const transcript = event.results[0][0].transcript;
                    console.log("üé§ Apple/Safari: Result received (restart):", transcript);
                    if (transcript) {
                      // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç, –Ω–æ –Ω–µ –≤—ã–∑—ã–≤–∞–µ–º onTranscript –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
                      lastTranscriptRef.current = (lastTranscriptRef.current + " " + transcript.trim()).trim();
                      console.log("üé§ Apple/Safari: Accumulated transcript:", lastTranscriptRef.current);
                    }
                  };
                  
                  recognitionRef.current = newAppleRec;
                  newAppleRec.start();
                } catch (e: any) {
                  console.error("üé§ Apple/Safari: Failed to restart recognition:", e);
                  hardResetFlags();
                }
              } else {
                hardResetFlags();
              }
            }, 100);
          } else {
            // –ï—Å–ª–∏ –±—ã–ª–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Ä—É—á–Ω—É—é, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
            if (lastTranscriptRef.current.trim() && stopRequestedRef.current) {
              console.log("üé§ Apple/Safari: Sending accumulated transcript on manual stop:", lastTranscriptRef.current.trim());
              onTranscriptRef.current?.(lastTranscriptRef.current.trim());
            }
          hardResetFlags();
          }
        };

        appleRec.onresult = (event: any) => {
          const transcript = event.results[0][0].transcript;
          console.log("üé§ Apple/Safari: Result received:", transcript);
          if (transcript) {
            // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç, –Ω–æ –Ω–µ –≤—ã–∑—ã–≤–∞–µ–º onTranscript –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            // onTranscript –±—É–¥–µ—Ç –≤—ã–∑–≤–∞–Ω —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —è–≤–Ω–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–µ (stopRequestedRef.current === true)
            lastTranscriptRef.current = transcript.trim();
            console.log("üé§ Apple/Safari: Transcript saved:", lastTranscriptRef.current);
          }
        };

        isStartingRef.current = true;
        stopRequestedRef.current = false;
        recognitionRef.current = appleRec; // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Å—ã–ª–∫—É –¥–ª—è stop()
        
        console.log("üé§ Apple/Safari: Calling start() on fresh instance");
        appleRec.start();
        return true;
      } catch (e: any) {
        console.error("üé§ Apple/Safari: Emergency start failed:", e);
        hardResetFlags();
        onErrorRef.current?.("start-failed", "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –¥–∏–∫—Ç–æ–≤–∫—É");
        return false;
      }
    }

    // –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö (Chrome/Android) –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      console.error("üé§ MediaDevices API is not available");
      onErrorRef.current?.("not-allowed", "–î–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ HTTPS –∏–ª–∏ –¥—Ä—É–≥–æ–π –±—Ä–∞—É–∑–µ—Ä.");
      return false;
    }

    // –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      // –°—Ä–∞–∑—É –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ—Ç–æ–∫, –Ω–∞–º –Ω—É–∂–Ω–æ —Ç–æ–ª—å–∫–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ
      stream.getTracks().forEach(track => track.stop());
      console.log("üé§ Microphone permission granted");
    } catch (err: any) {
      console.error("üé§ Microphone permission denied:", err);
      onErrorRef.current?.("not-allowed", "–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ");
      return false;
    }

    try {
      isStartingRef.current = true;
      stopRequestedRef.current = false;

      clearStartTimeout();
      
      // –ù–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö Apple –¥–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à—É—é –∑–∞–¥–µ—Ä–∂–∫—É –ø–µ—Ä–µ–¥ —Ä–µ–∞–ª—å–Ω—ã–º —Å—Ç–∞—Ä—Ç–æ–º, 
      // —á—Ç–æ–±—ã –∞—É–¥–∏–æ-—Å–µ—Å—Å–∏—è —É—Å–ø–µ–ª–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å—Å—è
      if (isAppleDevice) {
        await new Promise(resolve => setTimeout(resolve, 300));
      }

      // –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç –¥–æ 3 —Å–µ–∫—É–Ω–¥ –¥–ª—è –º–µ–¥–ª–µ–Ω–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤
      startTimeoutRef.current = window.setTimeout(() => {
        if (isStartingRef.current && !isRecording) {
          console.warn("üé§ start timeout -> abort + reset");
          try {
            rec.abort();
          } catch {
            /* no-op */
          }
          hardResetFlags();
          onErrorRef.current?.("start-timeout", "onstart –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, —Å—Ç–∞—Ä—Ç –∑–∞–≤–∏—Å");
        }
      }, 3000);

      console.log("üé§ Calling rec.start()");
      rec.start();
      return true;
    } catch (e: any) {
      console.error("üé§ Failed to start recording:", e);
      hardResetFlags();
      onErrorRef.current?.("start-failed", e?.message ?? "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å –≥–æ–ª–æ—Å–∞");
      return false;
    }
  }, [isRecording]);

  const stopRecording = useCallback(() => {
    const rec = recognitionRef.current;
    if (!rec) return;

    try {
      stopRequestedRef.current = true;
      clearStartTimeout();
      rec.stop();
    } catch {
      // –µ—Å–ª–∏ stop —É–ø–∞–ª ‚Äî –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –Ω–µ –æ—Å—Ç–∞–≤–ª—è–µ–º isStarting=true
      hardResetFlags();
      try {
        rec.abort();
      } catch {
        /* no-op */
      }
    }
  }, []);

  const toggleRecording = useCallback(async () => {
    if (isRecording) stopRecording();
    else await startRecording();
  }, [isRecording, startRecording, stopRecording]);

  return {
    isSupported,
    isRecording,
    isAppleDevice,
    startRecording,
    stopRecording,
    toggleRecording,
  };
};
