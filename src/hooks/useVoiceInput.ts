import { useState, useRef, useEffect, useCallback, useMemo } from "react";

/** types –æ—Å—Ç–∞–≤–ª—è—é –≤–∞—à–∏ –∫–∞–∫ –µ—Å—Ç—å */
interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
  resultIndex: number;
}
interface SpeechRecognitionErrorEvent extends Event {
  error: string;
  message?: string;
}
interface SpeechRecognitionResultList {
  readonly length: number;
  item(index: number): SpeechRecognitionResult;
  [index: number]: SpeechRecognitionResult;
}
interface SpeechRecognitionResult {
  readonly length: number;
  item(index: number): SpeechRecognitionAlternative;
  [index: number]: SpeechRecognitionAlternative;
  isFinal: boolean;
}
interface SpeechRecognitionAlternative {
  transcript: string;
  confidence: number;
}
interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  grammars: SpeechGrammarList;
  interimResults: boolean;
  lang: string;
  maxAlternatives: number;
  serviceURI: string;
  start(): void;
  stop(): void;
  abort(): void;
  onaudiostart: ((this: SpeechRecognition, ev: Event) => void) | null;
  onaudioend: ((this: SpeechRecognition, ev: Event) => void) | null;
  onend: ((this: SpeechRecognition, ev: Event) => void) | null;
  onerror: ((this: SpeechRecognition, ev: SpeechRecognitionErrorEvent) => void) | null;
  onnomatch: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => void) | null;
  onresult: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => void) | null;
  onsoundstart: ((this: SpeechRecognition, ev: Event) => void) | null;
  onsoundend: ((this: SpeechRecognition, ev: Event) => void) | null;
  onspeechstart: ((this: SpeechRecognition, ev: Event) => void) | null;
  onspeechend: ((this: SpeechRecognition, ev: Event) => void) | null;
  onstart: ((this: SpeechRecognition, ev: Event) => void) | null;
}
interface SpeechGrammarList {
  readonly length: number;
  item(index: number): SpeechGrammar;
  [index: number]: SpeechGrammar;
  addFromURI(src: string, weight?: number): void;
  addFromString(string: string, weight?: number): void;
}
interface SpeechGrammar {
  src: string;
  weight: number;
}

type VoiceErrorCode =
  | "not-allowed"
  | "no-speech"
  | "audio-capture"
  | "network"
  | "aborted"
  | "start-failed"
  | "start-timeout"
  | "not-supported"
  | string;

interface UseVoiceInputOptions {
  lang?: string;
  onTranscript?: (transcript: string) => void;
  onError?: (code: VoiceErrorCode, message?: string) => void;
}

interface UseVoiceInputReturn {
  isRecording: boolean;
  isSupported: boolean;
  isIOS: boolean;
  startRecording: () => Promise<boolean>;
  stopRecording: () => void;
  toggleRecording: () => void;
}

export const useVoiceInput = ({
  lang = "ru-RU",
  onTranscript,
  onError,
}: UseVoiceInputOptions = {}): UseVoiceInputReturn => {
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const lastTranscriptRef = useRef<string>("");

  const [isSupported, setIsSupported] = useState(false);
  const [isRecording, setIsRecording] = useState(false);

  // –ì–≤–∞—Ä–¥—ã –æ—Ç –≥–æ–Ω–æ–∫/–¥—É–±–ª–µ–π (refs = —Å—Ç–∞–±–∏–ª—å–Ω—ã–π mutex)
  const isStartingRef = useRef(false);
  const stopRequestedRef = useRef(false);
  const ignoreErrorsRef = useRef(false);

  // callbacks —á–µ—Ä–µ–∑ refs (—á—Ç–æ–±—ã –ù–ï –ø–µ—Ä–µ—Å–æ–∑–¥–∞–≤–∞—Ç—å recognition –ø—Ä–∏ –∫–∞–∂–¥–æ–º —Ä–µ–Ω–¥–µ—Ä–µ)
  const onTranscriptRef = useRef<typeof onTranscript>(onTranscript);
  const onErrorRef = useRef<typeof onError>(onError);

  // watchdog, —á—Ç–æ–±—ã isStarting –Ω–µ –º–æ–≥ –∑–∞–≤–∏—Å–Ω—É—Ç—å
  const startTimeoutRef = useRef<number | null>(null);

  const isIOS = useMemo(() => {
    if (typeof navigator === "undefined") return false;
    const ua = navigator.userAgent || "";
    const iOS = /iPad|iPhone|iPod/.test(ua);
    const iPadOS13Plus = navigator.platform === "MacIntel" && (navigator as any).maxTouchPoints > 1;
    return iOS || iPadOS13Plus;
  }, []);

  useEffect(() => {
    onTranscriptRef.current = onTranscript;
    onErrorRef.current = onError;
  }, [onTranscript, onError]);

  const clearStartTimeout = () => {
    if (startTimeoutRef.current) {
      window.clearTimeout(startTimeoutRef.current);
      startTimeoutRef.current = null;
    }
  };

  const hardResetFlags = () => {
    clearStartTimeout();
    isStartingRef.current = false;
    stopRequestedRef.current = false;
    setIsRecording(false);
  };

  const createRecognition = useCallback(() => {
    const w = window as any;
    const Ctor = w.SpeechRecognition || w.webkitSpeechRecognition;

    if (!Ctor) {
      console.warn("üé§ Speech Recognition API not available");
      setIsSupported(false);
      return null;
    }

    const rec: SpeechRecognition = new Ctor();
    rec.continuous = true; // –ò–∑–º–µ–Ω—è–µ–º –Ω–∞ true –¥–ª—è –ª—É—á—à–µ–≥–æ –∑–∞—Ö–≤–∞—Ç–∞
    rec.interimResults = true; // –í–∫–ª—é—á–∞–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    rec.lang = lang;

    rec.onstart = () => {
      console.log("üé§ Speech recognition started successfully");
      lastTranscriptRef.current = ""; // –°–±—Ä–æ—Å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
      clearStartTimeout();
      isStartingRef.current = false;
      stopRequestedRef.current = false;
      setIsRecording(true);
    };

    rec.onend = () => {
      console.log("üé§ Speech recognition ended", { lastTranscript: lastTranscriptRef.current });
      // –ï—Å–ª–∏ –æ—Å—Ç–∞–ª—Å—è –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–∏ —Ä—É—á–Ω–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–µ)
      if (lastTranscriptRef.current.trim() && stopRequestedRef.current) {
        console.log("üé§ Sending remaining transcript on manual stop:", lastTranscriptRef.current.trim());
        onTranscriptRef.current?.(lastTranscriptRef.current.trim());
      }
      hardResetFlags();
    };

    rec.onresult = (event: SpeechRecognitionEvent) => {
      let interimTranscript = "";
      let finalTranscript = "";

      for (let i = event.resultIndex; i < event.results.length; ++i) {
        const transcript = event.results[i][0].transcript;
        if (event.results[i].isFinal) {
          finalTranscript += transcript;
        } else {
          interimTranscript += transcript;
        }
      }

      const currentText = (finalTranscript || interimTranscript).trim();
      if (currentText) {
        lastTranscriptRef.current = currentText;
        console.log("üé§ Speech recognition update:", { final: finalTranscript, interim: interimTranscript });
      }

      if (finalTranscript.trim()) {
        console.log("üé§ Speech recognition result (final):", finalTranscript.trim());
        onTranscriptRef.current?.(finalTranscript.trim());
        lastTranscriptRef.current = ""; // –°–±—Ä–∞—Å—ã–≤–∞–µ–º, —Ç–∞–∫ –∫–∞–∫ —É–∂–µ –æ—Ç–ø—Ä–∞–≤–∏–ª–∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π
      }
    };

    rec.onerror = (event: SpeechRecognitionErrorEvent) => {
      const code = (event as any)?.error as VoiceErrorCode;
      const msg = (event as any)?.message as string | undefined;
      console.error("üé§ Speech recognition error:", { code, msg, event });

      if (ignoreErrorsRef.current) return;

      // aborted –ø—Ä–∏ stop/blur –Ω–∞ iOS ‚Äî –Ω–µ —ç—Å–∫–∞–ª–∏—Ä—É–µ–º
      if (code === "aborted" && (stopRequestedRef.current || isIOS)) {
        hardResetFlags();
        return;
      }

      hardResetFlags();
      onErrorRef.current?.(code, msg);
    };

    return rec;
  }, [lang, isIOS]);

  // –°–æ–∑–¥–∞—ë–º recognition —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —Å–º–µ–Ω–µ lang (–∞ –Ω–µ –ø—Ä–∏ –∫–∞–∂–¥–æ–º —Ä–µ–Ω–¥–µ—Ä–µ)
  useEffect(() => {
    ignoreErrorsRef.current = false;

    // –≤–∞–∂–Ω—ã–π reset –Ω–∞ –º–∞—É–Ω—Ç–µ —ç—Ñ—Ñ–µ–∫—Ç–∞ (–∑–∞–∫—Ä—ã–≤–∞–µ—Ç "–∑–∞–ª–∏–ø–∞–Ω–∏—è" –ø–æ—Å–ª–µ HMR/cleanup)
    hardResetFlags();

    const rec = createRecognition();
    if (!rec) return;

    recognitionRef.current = rec;
    setIsSupported(true);

    return () => {
      ignoreErrorsRef.current = true;

      // –∂—ë—Å—Ç–∫–æ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥–∏ –∑–¥–µ—Å—å, –ø–æ—Ç–æ–º—É —á—Ç–æ onend/onerror –º–æ–≥—É—Ç –Ω–µ —Å—Ä–∞–±–æ—Ç–∞—Ç—å
      hardResetFlags();

      try {
        rec.onstart = null as any;
        rec.onend = null as any;
        rec.onresult = null as any;
        rec.onerror = null as any;
        rec.onaudiostart = null as any;

        // abort –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ; stop —á–∞—Å—Ç–æ –¥–∞—ë—Ç –ª–∏—à–Ω–∏–µ aborted
        rec.abort();
      } catch {
        /* no-op */
      } finally {
        recognitionRef.current = null;
      }
    };
  }, [createRecognition]);

  const startRecording = useCallback(async (): Promise<boolean> => {
    const rec = recognitionRef.current;
    console.log("üé§ startRecording called, rec exists:", !!rec, "isStarting:", isStartingRef.current, "isRecording:", isRecording);

    if (!rec) {
      console.error("üé§ No recognition instance available");
      onErrorRef.current?.("not-supported", "SpeechRecognition instance –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç");
      return false;
    }

    if (isStartingRef.current || isRecording) {
      console.log("üé§ Recording already in progress or starting");
      return false;
    }

    // Check if mediaDevices API is available
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      console.error("üé§ MediaDevices API is not available");
      onErrorRef.current?.("not-allowed", "–î–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ HTTPS –∏–ª–∏ –¥—Ä—É–≥–æ–π –±—Ä–∞—É–∑–µ—Ä.");
      return false;
    }

    // –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      // –°—Ä–∞–∑—É –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ—Ç–æ–∫, –Ω–∞–º –Ω—É–∂–Ω–æ —Ç–æ–ª—å–∫–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ
      stream.getTracks().forEach(track => track.stop());
      console.log("üé§ Microphone permission granted");
    } catch (err: any) {
      console.error("üé§ Microphone permission denied:", err);
      onErrorRef.current?.("not-allowed", "–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ");
      return false;
    }

    try {
      isStartingRef.current = true;
      stopRequestedRef.current = false;

      clearStartTimeout();
      // –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç –¥–æ 3 —Å–µ–∫—É–Ω–¥ –¥–ª—è –º–µ–¥–ª–µ–Ω–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤
      startTimeoutRef.current = window.setTimeout(() => {
        if (isStartingRef.current && !isRecording) {
          console.warn("üé§ start timeout -> abort + reset");
          try {
            rec.abort();
          } catch {
            /* no-op */
          }
          hardResetFlags();
          onErrorRef.current?.("start-timeout", "onstart –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, —Å—Ç–∞—Ä—Ç –∑–∞–≤–∏—Å");
        }
      }, 3000);

      console.log("üé§ Calling rec.start()");
      rec.start();
      return true;
    } catch (e: any) {
      console.error("üé§ Failed to start recording:", e);
      hardResetFlags();
      onErrorRef.current?.("start-failed", e?.message ?? "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å –≥–æ–ª–æ—Å–∞");
      return false;
    }
  }, [isRecording]);

  const stopRecording = useCallback(() => {
    const rec = recognitionRef.current;
    if (!rec) return;

    try {
      stopRequestedRef.current = true;
      clearStartTimeout();
      rec.stop();
    } catch {
      // –µ—Å–ª–∏ stop —É–ø–∞–ª ‚Äî –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –Ω–µ –æ—Å—Ç–∞–≤–ª—è–µ–º isStarting=true
      hardResetFlags();
      try {
        rec.abort();
      } catch {
        /* no-op */
      }
    }
  }, []);

  const toggleRecording = useCallback(async () => {
    if (isRecording) stopRecording();
    else await startRecording();
  }, [isRecording, startRecording, stopRecording]);

  return {
    isSupported,
    isRecording,
    isIOS,
    startRecording,
    stopRecording,
    toggleRecording,
  };
};
